{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model\n",
    "\n",
    "In this notebook, we will train our model for predicting Sentiments. The model i choose are:\n",
    "\n",
    "- Multinomial Naive Bayes : since it's commonly used for text data due to it being based on the Bayes' Theorem\n",
    "- Logistic Regression : since it's one of the simple yet powerful classification machine learning model. But because this is a multiclass classification problem, i use One vs Rest Logistic Regression.\n",
    "- Random Forest : since it is one of the most robust machine learning model, i included Random Forest since it might be better to deal with our imbalanced classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(style ='whitegrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_curve, auc, roc_auc_score \n",
    "from sklearn.metrics import balanced_accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_sentiment = pickle.load(open('sentiment_words.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_title</th>\n",
       "      <th>stem_title</th>\n",
       "      <th>lemma_title</th>\n",
       "      <th>alpha_review</th>\n",
       "      <th>stem_review</th>\n",
       "      <th>lemma_review</th>\n",
       "      <th>alpha_combination</th>\n",
       "      <th>stem_combination</th>\n",
       "      <th>lemma_combination</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>some major design flaws</td>\n",
       "      <td>major design flaw</td>\n",
       "      <td>major design flaw</td>\n",
       "      <td>i had such high hopes for this dress and reall...</td>\n",
       "      <td>high hope dress realli want work initi order p...</td>\n",
       "      <td>high hope dress really wanted work initially o...</td>\n",
       "      <td>some major design flaws i had such high hopes ...</td>\n",
       "      <td>major design flaw high hope dress realli want ...</td>\n",
       "      <td>major design flaw high hope dress really wante...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my favorite buy</td>\n",
       "      <td>favorit buy</td>\n",
       "      <td>favorite buy</td>\n",
       "      <td>i love  love  love this jumpsuit  it s fun  fl...</td>\n",
       "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
       "      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n",
       "      <td>my favorite buy  i love  love  love this jumps...</td>\n",
       "      <td>favorit buy love love love jumpsuit fun flirti...</td>\n",
       "      <td>favorite buy love love love jumpsuit fun flirt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flattering shirt</td>\n",
       "      <td>flatter shirt</td>\n",
       "      <td>flatter shirt</td>\n",
       "      <td>this shirt is very flattering to all due to th...</td>\n",
       "      <td>shirt flatter due adjust front tie perfect len...</td>\n",
       "      <td>shirt flatter due adjustable front tie perfect...</td>\n",
       "      <td>flattering shirt this shirt is very flattering...</td>\n",
       "      <td>flatter shirt shirt flatter due adjust front t...</td>\n",
       "      <td>flatter shirt shirt flatter due adjustable fro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not for the very petite</td>\n",
       "      <td>petit</td>\n",
       "      <td>petite</td>\n",
       "      <td>i love tracy reese dresses  but this one is no...</td>\n",
       "      <td>love traci rees dress one petit feet tall usua...</td>\n",
       "      <td>love tracy reese dress one petite foot tall us...</td>\n",
       "      <td>not for the very petite i love tracy reese dre...</td>\n",
       "      <td>petit love traci rees dress one petit feet tal...</td>\n",
       "      <td>petite love tracy reese dress one petite foot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cagrcoal shimmer fun</td>\n",
       "      <td>cagrcoal shimmer fun</td>\n",
       "      <td>cagrcoal shimmer fun</td>\n",
       "      <td>i aded this in my basket at hte last mintue to...</td>\n",
       "      <td>ade basket hte last mintu see would look like ...</td>\n",
       "      <td>aded basket hte last mintue see would look lik...</td>\n",
       "      <td>cagrcoal shimmer fun i aded this in my basket ...</td>\n",
       "      <td>cagrcoal shimmer fun ade basket hte last mintu...</td>\n",
       "      <td>cagrcoal shimmer fun aded basket hte last mint...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               alpha_title            stem_title           lemma_title  \\\n",
       "0  some major design flaws     major design flaw     major design flaw   \n",
       "1         my favorite buy            favorit buy          favorite buy   \n",
       "2         flattering shirt         flatter shirt         flatter shirt   \n",
       "3  not for the very petite                 petit                petite   \n",
       "4     cagrcoal shimmer fun  cagrcoal shimmer fun  cagrcoal shimmer fun   \n",
       "\n",
       "                                        alpha_review  \\\n",
       "0  i had such high hopes for this dress and reall...   \n",
       "1  i love  love  love this jumpsuit  it s fun  fl...   \n",
       "2  this shirt is very flattering to all due to th...   \n",
       "3  i love tracy reese dresses  but this one is no...   \n",
       "4  i aded this in my basket at hte last mintue to...   \n",
       "\n",
       "                                         stem_review  \\\n",
       "0  high hope dress realli want work initi order p...   \n",
       "1  love love love jumpsuit fun flirti fabul everi...   \n",
       "2  shirt flatter due adjust front tie perfect len...   \n",
       "3  love traci rees dress one petit feet tall usua...   \n",
       "4  ade basket hte last mintu see would look like ...   \n",
       "\n",
       "                                        lemma_review  \\\n",
       "0  high hope dress really wanted work initially o...   \n",
       "1  love love love jumpsuit fun flirty fabulous ev...   \n",
       "2  shirt flatter due adjustable front tie perfect...   \n",
       "3  love tracy reese dress one petite foot tall us...   \n",
       "4  aded basket hte last mintue see would look lik...   \n",
       "\n",
       "                                   alpha_combination  \\\n",
       "0  some major design flaws i had such high hopes ...   \n",
       "1  my favorite buy  i love  love  love this jumps...   \n",
       "2  flattering shirt this shirt is very flattering...   \n",
       "3  not for the very petite i love tracy reese dre...   \n",
       "4  cagrcoal shimmer fun i aded this in my basket ...   \n",
       "\n",
       "                                    stem_combination  \\\n",
       "0  major design flaw high hope dress realli want ...   \n",
       "1  favorit buy love love love jumpsuit fun flirti...   \n",
       "2  flatter shirt shirt flatter due adjust front t...   \n",
       "3  petit love traci rees dress one petit feet tal...   \n",
       "4  cagrcoal shimmer fun ade basket hte last mintu...   \n",
       "\n",
       "                                   lemma_combination  Sentiment  \n",
       "0  major design flaw high hope dress really wante...          1  \n",
       "1  favorite buy love love love jumpsuit fun flirt...          2  \n",
       "2  flatter shirt shirt flatter due adjustable fro...          2  \n",
       "3  petite love tracy reese dress one petite foot ...          0  \n",
       "4  cagrcoal shimmer fun aded basket hte last mint...          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sentiment.drop('Sentiment', axis=1)\n",
    "y = df_sentiment['Sentiment']\n",
    "\n",
    "alpha_title_train, alpha_title_test, alpha_title_y_train, alpha_title_y_test = train_test_split(X['alpha_title'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "stem_title_train, stem_title_test, stem_title_y_train, stem_title_y_test = train_test_split(X['stem_title'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "lemma_title_train, lemma_title_test, lemma_title_y_train, lemma_title_y_test = train_test_split(X['lemma_title'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "alpha_review_train, alpha_review_test, alpha_review_y_train, alpha_review_y_test = train_test_split(X['alpha_review'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "stem_review_train, stem_review_test, stem_review_y_train, stem_review_y_test = train_test_split(X['stem_review'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "lemma_review_train, lemma_review_test, lemma_review_y_train, lemma_review_y_test = train_test_split(X['lemma_review'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "alpha_combination_train, alpha_combination_test, alpha_combination_y_train, alpha_combination_y_test = train_test_split(X['alpha_combination'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "stem_combination_train, stem_combination_test, stem_combination_y_train, stem_combination_y_test = train_test_split(X['stem_combination'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "lemma_combination_train, lemma_combination_test, lemma_combination_y_train, lemma_combination_y_test = train_test_split(X['lemma_combination'], y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [alpha_title_train, stem_title_train, lemma_title_train,\n",
    "           alpha_review_train, stem_review_train, lemma_review_train,\n",
    "           alpha_combination_train, stem_combination_train, lemma_combination_train]\n",
    "y_train = [alpha_title_y_train, stem_title_y_train, lemma_title_y_train,\n",
    "           alpha_review_y_train, stem_review_y_train, lemma_review_y_train,\n",
    "           alpha_combination_y_train, stem_combination_y_train, lemma_combination_y_train]\n",
    "\n",
    "X_test = [alpha_title_test, stem_title_test, lemma_title_test,\n",
    "           alpha_review_test, stem_review_test, lemma_review_test,\n",
    "           alpha_combination_test, stem_combination_test, lemma_combination_test]\n",
    "y_test = [alpha_title_y_test, stem_title_y_test, lemma_title_y_test,\n",
    "           alpha_review_y_test, stem_review_y_test, lemma_review_y_test,\n",
    "           alpha_combination_y_test, stem_combination_y_test, lemma_combination_y_test]\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "index_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_error(X_train, y_train, model):\n",
    "    predictions = model.predict(X_train)\n",
    "    predictProba = model.predict_proba(X_train)\n",
    "    ROC_AUC_Score_macro = roc_auc_score(y_train, predictProba, multi_class='ovr', average='macro')\n",
    "    ROC_AUC_Score_weighted = roc_auc_score(y_train, predictProba, multi_class='ovr', average='weighted')\n",
    "    f1_macro = f1_score(y_train, predictions, average ='macro')\n",
    "    f1_weighted = f1_score(y_train, predictions, average ='weighted')\n",
    "    accuracy = balanced_accuracy_score(y_train, predictions)\n",
    "    logloss = log_loss(y_train, predictProba)\n",
    "    return{\n",
    "        'ROC AUC Macro Train' : ROC_AUC_Score_macro,\n",
    "        'ROC AUC Weighted Train' : ROC_AUC_Score_weighted,\n",
    "        'F1 Macro Train' : f1_macro,\n",
    "        'F1 Weighted Train' : f1_weighted,\n",
    "        'Balanced Accuracy Score Train': accuracy,\n",
    "        'Log Loss Train' : logloss\n",
    "    }\n",
    "def calc_validation_error(X_test, y_test, model):\n",
    "    predictions = model.predict(X_test)\n",
    "    predictProba = model.predict_proba(X_test)\n",
    "    ROC_AUC_Score_macro = roc_auc_score(y_test, predictProba, multi_class='ovr', average='macro')\n",
    "    ROC_AUC_Score_weighted = roc_auc_score(y_test, predictProba, multi_class='ovr', average='weighted')\n",
    "    f1_macro = f1_score(y_test, predictions, average ='macro')\n",
    "    f1_weighted = f1_score(y_test, predictions, average ='weighted')\n",
    "    accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "    logloss = log_loss(y_test,predictProba)\n",
    "    return{\n",
    "        'ROC AUC Macro Test' : ROC_AUC_Score_macro,\n",
    "        'ROC AUC Weighted Test' : ROC_AUC_Score_weighted,\n",
    "        'F1 Macro Test' : f1_macro,\n",
    "        'F1 Weighted Test' : f1_weighted,\n",
    "        'Balanced Accuracy Score Test': accuracy,\n",
    "        'Log Loss Test' : logloss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_multiNB = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "tuned_parameters_nb = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__max_features' : [10000, 15000, 20000, 25000, 30000, None],\n",
    "    'clf__alpha': [1, 1e-1, 1e-2]\n",
    "}\n",
    "\n",
    "gs_multiNB = GridSearchCV(pipeline_multiNB, tuned_parameters_nb, cv=5, n_jobs=-1, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "\n",
      "Feature :  alpha_title\n",
      "Best Score :  0.6082904828217878\n",
      "Best Params :  {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.6125669646419161\n",
      "\n",
      "\n",
      "Feature :  stem_title\n",
      "Best Score :  0.5499422518199724\n",
      "Best Params :  {'clf__alpha': 0.01, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5415160580943491\n",
      "\n",
      "\n",
      "Feature :  lemma_title\n",
      "Best Score :  0.5454794060174709\n",
      "Best Params :  {'clf__alpha': 0.01, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.537544707862692\n",
      "\n",
      "\n",
      "Feature :  alpha_review\n",
      "Best Score :  0.6549110594199856\n",
      "Best Params :  {'clf__alpha': 1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.6813790004373798\n",
      "\n",
      "\n",
      "Feature :  stem_review\n",
      "Best Score :  0.6189173882724794\n",
      "Best Params :  {'clf__alpha': 1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.6303411029295943\n",
      "\n",
      "\n",
      "Feature :  lemma_review\n",
      "Best Score :  0.6167497957861243\n",
      "Best Params :  {'clf__alpha': 1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.6135043726466437\n",
      "\n",
      "\n",
      "Feature :  alpha_combination\n",
      "Best Score :  0.6822313606852055\n",
      "Best Params :  {'clf__alpha': 1, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.6954987330601589\n",
      "\n",
      "\n",
      "Feature :  stem_combination\n",
      "Best Score :  0.6545833919262962\n",
      "Best Params :  {'clf__alpha': 1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.6613393054065482\n",
      "\n",
      "\n",
      "Feature :  lemma_combination\n",
      "Best Score :  0.6519007444764304\n",
      "Best Params :  {'clf__alpha': 1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.6488225048564363\n",
      "\n",
      "\n",
      "Wall time: 18min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = '_multi_nb'\n",
    "print('Multinomial Naive Bayes\\n')\n",
    "for x, y, x_test, y_true in zip(X_train, y_train, X_test, y_test):\n",
    "    gs = gs_multiNB.fit(x, y)\n",
    "    print('Feature : ', x.name)\n",
    "    print('Best Score : ', gs.best_score_)\n",
    "    print('Best Params : ', gs.best_params_)\n",
    "    y_score = gs.best_estimator_.predict(x_test)\n",
    "    eval_score = balanced_accuracy_score(y_true, y_score)\n",
    "    print('Balanced Accuracy Score on Test Data : ', eval_score)\n",
    "    train_score.append(calc_train_error(x, y, gs.best_estimator_))\n",
    "    test_score.append(calc_validation_error(x_test, y_true, gs.best_estimator_))\n",
    "    index_name.append(x.name+model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_multiNB_tfidf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "tuned_parameters_nb_tfidf = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__max_features' : [10000, 15000, 20000, 25000, 30000, None],\n",
    "    'clf__alpha': [1, 1e-1, 1e-2]\n",
    "}\n",
    "\n",
    "gs_multiNB_tfidf = GridSearchCV(pipeline_multiNB_tfidf, tuned_parameters_nb_tfidf, cv=5, n_jobs=-1, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "\n",
      "Feature :  alpha_title\n",
      "Best Score :  0.5770521099771455\n",
      "Best Params :  {'clf__alpha': 0.01, 'vect__max_features': 20000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5831539724936139\n",
      "\n",
      "\n",
      "Feature :  stem_title\n",
      "Best Score :  0.5348789565680047\n",
      "Best Params :  {'clf__alpha': 0.01, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.535527860551703\n",
      "\n",
      "\n",
      "Feature :  lemma_title\n",
      "Best Score :  0.5291431100444619\n",
      "Best Params :  {'clf__alpha': 0.01, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5319296196268565\n",
      "\n",
      "\n",
      "Feature :  alpha_review\n",
      "Best Score :  0.5374323931645669\n",
      "Best Params :  {'clf__alpha': 0.1, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5410863787085661\n",
      "\n",
      "\n",
      "Feature :  stem_review\n",
      "Best Score :  0.4743522154779944\n",
      "Best Params :  {'clf__alpha': 0.1, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.4834891687374181\n",
      "\n",
      "\n",
      "Feature :  lemma_review\n",
      "Best Score :  0.4724774224733165\n",
      "Best Params :  {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.4754105181445234\n",
      "\n",
      "\n",
      "Feature :  alpha_combination\n",
      "Best Score :  0.5635843583613733\n",
      "Best Params :  {'clf__alpha': 0.1, 'vect__max_features': 20000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5762220790242337\n",
      "\n",
      "\n",
      "Feature :  stem_combination\n",
      "Best Score :  0.5130776703574631\n",
      "Best Params :  {'clf__alpha': 0.1, 'vect__max_features': 20000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5238385096228738\n",
      "\n",
      "\n",
      "Feature :  lemma_combination\n",
      "Best Score :  0.5119426462422352\n",
      "Best Params :  {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5131490193608312\n",
      "\n",
      "\n",
      "Wall time: 20min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = '_multi_nb_tfidf'\n",
    "print('Multinomial Naive Bayes\\n')\n",
    "for x, y, x_test, y_true in zip(X_train, y_train, X_test, y_test):\n",
    "    gs = gs_multiNB_tfidf.fit(x, y)\n",
    "    print('Feature : ', x.name)\n",
    "    print('Best Score : ', gs.best_score_)\n",
    "    print('Best Params : ', gs.best_params_)\n",
    "    y_score = gs.best_estimator_.predict(x_test)\n",
    "    eval_score = balanced_accuracy_score(y_true, y_score)\n",
    "    print('Balanced Accuracy Score on Test Data : ', eval_score)\n",
    "    train_score.append(calc_train_error(x, y, gs.best_estimator_))\n",
    "    test_score.append(calc_validation_error(x_test, y_true, gs.best_estimator_))\n",
    "    index_name.append(x.name+model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logReg = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', LogisticRegression(multi_class='ovr'))])\n",
    "\n",
    "tuned_parameters_lr = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__max_features' : [10000, 15000, 20000, 25000, 30000, None],\n",
    "    'clf__solver': ['sag', 'saga', 'lbfgs'],\n",
    "    'clf__penalty': ['l2', 'none'],\n",
    "    'clf__max_iter' : [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "gs_logReg = GridSearchCV(pipeline_logReg, tuned_parameters_lr, cv=5, n_jobs=-1, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression OVR\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  alpha_title\n",
      "Best Score :  0.5747583843907813\n",
      "Best Params :  {'clf__max_iter': 400, 'clf__penalty': 'none', 'clf__solver': 'sag', 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5681698010328352\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  stem_title\n",
      "Best Score :  0.5487856383076776\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5523027421003811\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  lemma_title\n",
      "Best Score :  0.5484133521010106\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5485244403780699\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  alpha_review\n",
      "Best Score :  0.5779432844783153\n",
      "Best Params :  {'clf__max_iter': 300, 'clf__penalty': 'none', 'clf__solver': 'saga', 'vect__max_features': 25000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5931432139281592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  stem_review\n",
      "Best Score :  0.5642023578041405\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'sag', 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5676085921600521\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  lemma_review\n",
      "Best Score :  0.5561915319925543\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'l2', 'clf__solver': 'saga', 'vect__max_features': 20000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5574722801634712\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  alpha_combination\n",
      "Best Score :  0.6054689909176146\n",
      "Best Params :  {'clf__max_iter': 300, 'clf__penalty': 'none', 'clf__solver': 'saga', 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.619404473447632\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  stem_combination\n",
      "Best Score :  0.5965388597953925\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'saga', 'vect__max_features': 30000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5844512050260895\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  lemma_combination\n",
      "Best Score :  0.5955359503898247\n",
      "Best Params :  {'clf__max_iter': 200, 'clf__penalty': 'none', 'clf__solver': 'saga', 'vect__max_features': 20000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5819102446985355\n",
      "\n",
      "\n",
      "Wall time: 21h 47min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = '_logReg_OVR'\n",
    "print('Logistic Regression OVR\\n')\n",
    "for x, y, x_test, y_true in zip(X_train, y_train, X_test, y_test):\n",
    "    gs = gs_logReg.fit(x, y)\n",
    "    print('Feature : ', x.name)\n",
    "    print('Best Score : ', gs.best_score_)\n",
    "    print('Best Params : ', gs.best_params_)\n",
    "    y_score = gs.best_estimator_.predict(x_test)\n",
    "    eval_score = balanced_accuracy_score(y_true, y_score)\n",
    "    print('Balanced Accuracy Score on Test Data : ', eval_score)\n",
    "    train_score.append(calc_train_error(x, y, gs.best_estimator_))\n",
    "    test_score.append(calc_validation_error(x_test, y_true, gs.best_estimator_))\n",
    "    index_name.append(x.name+model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logReg_tfidf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression(multi_class='ovr'))])\n",
    "\n",
    "tuned_parameters_lr_tfidf = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__max_features' : [10000, 15000, 20000, 25000, 30000, None],\n",
    "    'clf__solver': ['sag', 'saga', 'lbfgs'],\n",
    "    'clf__penalty': ['l2', 'none'],\n",
    "    'clf__max_iter' : [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "gs_logReg_tfidf = GridSearchCV(pipeline_logReg_tfidf, tuned_parameters_lr_tfidf, cv=5, n_jobs=-1, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression OVR\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  alpha_title\n",
      "Best Score :  0.5788747999737006\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5743128108388432\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  stem_title\n",
      "Best Score :  0.5499655634048717\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5586168484568196\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  lemma_title\n",
      "Best Score :  0.5441449702881307\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5529234204495901\n",
      "\n",
      "\n",
      "Feature :  alpha_review\n",
      "Best Score :  0.584235169403945\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5824070351515189\n",
      "\n",
      "\n",
      "Feature :  stem_review\n",
      "Best Score :  0.562311945657589\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5577800455719555\n",
      "\n",
      "\n",
      "Feature :  lemma_review\n",
      "Best Score :  0.5585882843801571\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5564466426617886\n",
      "\n",
      "\n",
      "Feature :  alpha_combination\n",
      "Best Score :  0.6091643376862181\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.6222107327227863\n",
      "\n",
      "\n",
      "Feature :  stem_combination\n",
      "Best Score :  0.5953350333433222\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': 30000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5952784963747657\n",
      "\n",
      "\n",
      "Feature :  lemma_combination\n",
      "Best Score :  0.590639208372502\n",
      "Best Params :  {'clf__max_iter': 100, 'clf__penalty': 'none', 'clf__solver': 'lbfgs', 'vect__max_features': 30000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5863004672730744\n",
      "\n",
      "\n",
      "Wall time: 14h 43min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = '_logReg_OVR_tfidf'\n",
    "print('Logistic Regression OVR\\n')\n",
    "for x, y, x_test, y_true in zip(X_train, y_train, X_test, y_test):\n",
    "    gs = gs_logReg_tfidf.fit(x, y)\n",
    "    print('Feature : ', x.name)\n",
    "    print('Best Score : ', gs.best_score_)\n",
    "    print('Best Params : ', gs.best_params_)\n",
    "    y_score = gs.best_estimator_.predict(x_test)\n",
    "    eval_score = balanced_accuracy_score(y_true, y_score)\n",
    "    print('Balanced Accuracy Score on Test Data : ', eval_score)\n",
    "    train_score.append(calc_train_error(x, y, gs.best_estimator_))\n",
    "    test_score.append(calc_validation_error(x_test, y_true, gs.best_estimator_))\n",
    "    index_name.append(x.name+model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_RandomForest = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', RandomForestClassifier(random_state=0, n_jobs=-1))])\n",
    "\n",
    "tuned_parameters_randomforest = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__max_features' : [10000, 15000, 20000, 25000, 30000, None],\n",
    "    'clf__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'clf__n_estimators' : [100, 200, 300]\n",
    "}\n",
    "\n",
    "gs_RandomForest = GridSearchCV(pipeline_RandomForest, tuned_parameters_randomforest, cv=5, n_jobs=-1, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "Feature :  alpha_title\n",
      "Best Score :  0.5597220131710363\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 300, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5660137070170789\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  stem_title\n",
      "Best Score :  0.5506976855608879\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 300, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Balanced Accuracy Score on Test Data :  0.5496177928747392\n",
      "\n",
      "\n",
      "Feature :  lemma_title\n",
      "Best Score :  0.5441184442229801\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 200, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Balanced Accuracy Score on Test Data :  0.5460195519498926\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  alpha_review\n",
      "Best Score :  0.4151530389610049\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.4058631774178408\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  stem_review\n",
      "Best Score :  0.44991463872891774\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 300, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.45356287061545225\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  lemma_review\n",
      "Best Score :  0.4468911422428796\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.443633512157439\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  alpha_combination\n",
      "Best Score :  0.4286152661544932\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.4367303787085879\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  stem_combination\n",
      "Best Score :  0.4780002665034835\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.48629819628696597\n",
      "\n",
      "\n",
      "Feature :  lemma_combination\n",
      "Best Score :  0.4699570247566217\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 300, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.4764233665231914\n",
      "\n",
      "\n",
      "Wall time: 1d 19h 7min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = '_RandomForest'\n",
    "print('Random Forest\\n')\n",
    "for x, y, x_test, y_true in zip(X_train, y_train, X_test, y_test):\n",
    "    gs = gs_RandomForest.fit(x, y)\n",
    "    print('Feature : ', x.name)\n",
    "    print('Best Score : ', gs.best_score_)\n",
    "    print('Best Params : ', gs.best_params_)\n",
    "    y_score = gs.best_estimator_.predict(x_test)\n",
    "    eval_score = balanced_accuracy_score(y_true, y_score)\n",
    "    print('Balanced Accuracy Score on Test Data : ', eval_score)\n",
    "    train_score.append(calc_train_error(x, y, gs.best_estimator_))\n",
    "    test_score.append(calc_validation_error(x_test, y_true, gs.best_estimator_))\n",
    "    index_name.append(x.name+model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_RandomForest_tfidf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),        \n",
    "                     ('clf', RandomForestClassifier(random_state=0, n_jobs=-1))])\n",
    "\n",
    "tuned_parameters_randomforest_tfidf = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__max_features' : [10000, 15000, 20000, 25000, 30000, None],\n",
    "    'clf__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'clf__n_estimators' : [100, 200, 300]\n",
    "}\n",
    "\n",
    "gs_RandomForest_tfidf = GridSearchCV(pipeline_RandomForest_tfidf, tuned_parameters_randomforest_tfidf, cv=5, n_jobs=-1, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "Feature :  alpha_title\n",
      "Best Score :  0.5447798273872929\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 300, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5513781232186681\n",
      "\n",
      "\n",
      "Feature :  stem_title\n",
      "Best Score :  0.5426439715099719\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 300, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.536194301936983\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  lemma_title\n",
      "Best Score :  0.5344687461702133\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 300, 'vect__max_features': 15000, 'vect__ngram_range': (1, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.5393656317504402\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  alpha_review\n",
      "Best Score :  0.40921258425890716\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.41449757596172415\n",
      "\n",
      "\n",
      "Feature :  stem_review\n",
      "Best Score :  0.4387364229641836\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.4383309315234085\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :  lemma_review\n",
      "Best Score :  0.4340025345423328\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.42831427720815324\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = '_RandomForest_tfidf'\n",
    "print('Random Forest\\n')\n",
    "for x, y, x_test, y_true in zip(X_train[:6], y_train[:6], X_test[:6], y_test[:6] thinking):\n",
    "    gs = gs_RandomForest_tfidf.fit(x, y)\n",
    "    print('Feature : ', x.name)\n",
    "    print('Best Score : ', gs.best_score_)\n",
    "    print('Best Params : ', gs.best_params_)\n",
    "    y_score = gs.best_estimator_.predict(x_test)\n",
    "    eval_score = balanced_accuracy_score(y_true, y_score)\n",
    "    print('Balanced Accuracy Score on Test Data : ', eval_score)\n",
    "    train_score.append(calc_train_error(x, y, gs.best_estimator_))\n",
    "    test_score.append(calc_validation_error(x_test, y_true, gs.best_estimator_))\n",
    "    index_name.append(x.name+model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "Feature :  alpha_combination\n",
      "Best Score :  0.43157368560101333\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.43790278970512486\n",
      "\n",
      "\n",
      "Feature :  stem_combination\n",
      "Best Score :  0.47379821911529857\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 100, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.4749618536630851\n",
      "\n",
      "\n",
      "Feature :  lemma_combination\n",
      "Best Score :  0.46781469248798146\n",
      "Best Params :  {'clf__max_depth': None, 'clf__n_estimators': 200, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Balanced Accuracy Score on Test Data :  0.4671397445208094\n",
      "\n",
      "\n",
      "Wall time: 16h 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = '_RandomForest_tfidf'\n",
    "print('Random Forest\\n')\n",
    "for x, y, x_test, y_true in zip(X_train[6:], y_train[6:], X_test[6:], y_test[6:]):\n",
    "    gs = gs_RandomForest_tfidf.fit(x, y)\n",
    "    print('Feature : ', x.name)\n",
    "    print('Best Score : ', gs.best_score_)\n",
    "    print('Best Params : ', gs.best_params_)\n",
    "    y_score = gs.best_estimator_.predict(x_test)\n",
    "    eval_score = balanced_accuracy_score(y_true, y_score)\n",
    "    print('Balanced Accuracy Score on Test Data : ', eval_score)\n",
    "    train_score.append(calc_train_error(x, y, gs.best_estimator_))\n",
    "    test_score.append(calc_validation_error(x_test, y_true, gs.best_estimator_))\n",
    "    index_name.append(x.name+model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(train_score, open('train_score.sav', 'wb'))\n",
    "pickle.dump(test_score, open('test_score.sav', 'wb'))\n",
    "pickle.dump(index_name, open('index_name.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
