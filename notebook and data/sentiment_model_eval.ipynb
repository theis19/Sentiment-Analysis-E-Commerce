{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Results\n",
    "\n",
    "Looking at the results below, it seems the best model we will use for this case is Multinomial Naive Bayes on Alphabet-Only Text without TF-IDF. Besides looking at the results, it's also because Multinomial Naive Bayes doesn't consume as much time as the other models we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style(style ='whitegrid')\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_curve, auc, roc_auc_score \n",
    "from sklearn.metrics import balanced_accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_score = pickle.load(open('train_score.sav', 'rb'))\n",
    "test_score = pickle.load(open('test_score.sav', 'rb'))\n",
    "index_name = pickle.load(open('index_name.sav', 'rb'))\n",
    "df_sentiment = pickle.load(open('sentiment_words.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_title</th>\n",
       "      <th>stem_title</th>\n",
       "      <th>lemma_title</th>\n",
       "      <th>alpha_review</th>\n",
       "      <th>stem_review</th>\n",
       "      <th>lemma_review</th>\n",
       "      <th>alpha_combination</th>\n",
       "      <th>stem_combination</th>\n",
       "      <th>lemma_combination</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>some major design flaws</td>\n",
       "      <td>major design flaw</td>\n",
       "      <td>major design flaw</td>\n",
       "      <td>i had such high hopes for this dress and reall...</td>\n",
       "      <td>high hope dress realli want work initi order p...</td>\n",
       "      <td>high hope dress really wanted work initially o...</td>\n",
       "      <td>some major design flaws i had such high hopes ...</td>\n",
       "      <td>major design flaw high hope dress realli want ...</td>\n",
       "      <td>major design flaw high hope dress really wante...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my favorite buy</td>\n",
       "      <td>favorit buy</td>\n",
       "      <td>favorite buy</td>\n",
       "      <td>i love  love  love this jumpsuit  it s fun  fl...</td>\n",
       "      <td>love love love jumpsuit fun flirti fabul everi...</td>\n",
       "      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n",
       "      <td>my favorite buy  i love  love  love this jumps...</td>\n",
       "      <td>favorit buy love love love jumpsuit fun flirti...</td>\n",
       "      <td>favorite buy love love love jumpsuit fun flirt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flattering shirt</td>\n",
       "      <td>flatter shirt</td>\n",
       "      <td>flatter shirt</td>\n",
       "      <td>this shirt is very flattering to all due to th...</td>\n",
       "      <td>shirt flatter due adjust front tie perfect len...</td>\n",
       "      <td>shirt flatter due adjustable front tie perfect...</td>\n",
       "      <td>flattering shirt this shirt is very flattering...</td>\n",
       "      <td>flatter shirt shirt flatter due adjust front t...</td>\n",
       "      <td>flatter shirt shirt flatter due adjustable fro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not for the very petite</td>\n",
       "      <td>petit</td>\n",
       "      <td>petite</td>\n",
       "      <td>i love tracy reese dresses  but this one is no...</td>\n",
       "      <td>love traci rees dress one petit feet tall usua...</td>\n",
       "      <td>love tracy reese dress one petite foot tall us...</td>\n",
       "      <td>not for the very petite i love tracy reese dre...</td>\n",
       "      <td>petit love traci rees dress one petit feet tal...</td>\n",
       "      <td>petite love tracy reese dress one petite foot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cagrcoal shimmer fun</td>\n",
       "      <td>cagrcoal shimmer fun</td>\n",
       "      <td>cagrcoal shimmer fun</td>\n",
       "      <td>i aded this in my basket at hte last mintue to...</td>\n",
       "      <td>ade basket hte last mintu see would look like ...</td>\n",
       "      <td>aded basket hte last mintue see would look lik...</td>\n",
       "      <td>cagrcoal shimmer fun i aded this in my basket ...</td>\n",
       "      <td>cagrcoal shimmer fun ade basket hte last mintu...</td>\n",
       "      <td>cagrcoal shimmer fun aded basket hte last mint...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               alpha_title            stem_title           lemma_title  \\\n",
       "0  some major design flaws     major design flaw     major design flaw   \n",
       "1         my favorite buy            favorit buy          favorite buy   \n",
       "2         flattering shirt         flatter shirt         flatter shirt   \n",
       "3  not for the very petite                 petit                petite   \n",
       "4     cagrcoal shimmer fun  cagrcoal shimmer fun  cagrcoal shimmer fun   \n",
       "\n",
       "                                        alpha_review  \\\n",
       "0  i had such high hopes for this dress and reall...   \n",
       "1  i love  love  love this jumpsuit  it s fun  fl...   \n",
       "2  this shirt is very flattering to all due to th...   \n",
       "3  i love tracy reese dresses  but this one is no...   \n",
       "4  i aded this in my basket at hte last mintue to...   \n",
       "\n",
       "                                         stem_review  \\\n",
       "0  high hope dress realli want work initi order p...   \n",
       "1  love love love jumpsuit fun flirti fabul everi...   \n",
       "2  shirt flatter due adjust front tie perfect len...   \n",
       "3  love traci rees dress one petit feet tall usua...   \n",
       "4  ade basket hte last mintu see would look like ...   \n",
       "\n",
       "                                        lemma_review  \\\n",
       "0  high hope dress really wanted work initially o...   \n",
       "1  love love love jumpsuit fun flirty fabulous ev...   \n",
       "2  shirt flatter due adjustable front tie perfect...   \n",
       "3  love tracy reese dress one petite foot tall us...   \n",
       "4  aded basket hte last mintue see would look lik...   \n",
       "\n",
       "                                   alpha_combination  \\\n",
       "0  some major design flaws i had such high hopes ...   \n",
       "1  my favorite buy  i love  love  love this jumps...   \n",
       "2  flattering shirt this shirt is very flattering...   \n",
       "3  not for the very petite i love tracy reese dre...   \n",
       "4  cagrcoal shimmer fun i aded this in my basket ...   \n",
       "\n",
       "                                    stem_combination  \\\n",
       "0  major design flaw high hope dress realli want ...   \n",
       "1  favorit buy love love love jumpsuit fun flirti...   \n",
       "2  flatter shirt shirt flatter due adjust front t...   \n",
       "3  petit love traci rees dress one petit feet tal...   \n",
       "4  cagrcoal shimmer fun ade basket hte last mintu...   \n",
       "\n",
       "                                   lemma_combination  Sentiment  \n",
       "0  major design flaw high hope dress really wante...          1  \n",
       "1  favorite buy love love love jumpsuit fun flirt...          2  \n",
       "2  flatter shirt shirt flatter due adjustable fro...          2  \n",
       "3  petite love tracy reese dress one petite foot ...          0  \n",
       "4  cagrcoal shimmer fun aded basket hte last mint...          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Macro Train</th>\n",
       "      <th>ROC AUC Weighted Train</th>\n",
       "      <th>F1 Macro Train</th>\n",
       "      <th>F1 Weighted Train</th>\n",
       "      <th>Balanced Accuracy Score Train</th>\n",
       "      <th>Log Loss Train</th>\n",
       "      <th>ROC AUC Macro Test</th>\n",
       "      <th>ROC AUC Weighted Test</th>\n",
       "      <th>F1 Macro Test</th>\n",
       "      <th>F1 Weighted Test</th>\n",
       "      <th>Balanced Accuracy Score Test</th>\n",
       "      <th>Log Loss Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_title_multi_nb</th>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.963244</td>\n",
       "      <td>0.787137</td>\n",
       "      <td>0.889634</td>\n",
       "      <td>0.809898</td>\n",
       "      <td>3.585237e-01</td>\n",
       "      <td>0.858539</td>\n",
       "      <td>0.886654</td>\n",
       "      <td>0.607603</td>\n",
       "      <td>0.804344</td>\n",
       "      <td>0.612567</td>\n",
       "      <td>0.731238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_multi_nb</th>\n",
       "      <td>0.976582</td>\n",
       "      <td>0.978413</td>\n",
       "      <td>0.830715</td>\n",
       "      <td>0.913079</td>\n",
       "      <td>0.817315</td>\n",
       "      <td>2.156241e-01</td>\n",
       "      <td>0.818239</td>\n",
       "      <td>0.845558</td>\n",
       "      <td>0.552984</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.541516</td>\n",
       "      <td>0.854089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_multi_nb</th>\n",
       "      <td>0.977258</td>\n",
       "      <td>0.978986</td>\n",
       "      <td>0.831715</td>\n",
       "      <td>0.913593</td>\n",
       "      <td>0.820252</td>\n",
       "      <td>2.144713e-01</td>\n",
       "      <td>0.817842</td>\n",
       "      <td>0.845740</td>\n",
       "      <td>0.549183</td>\n",
       "      <td>0.778411</td>\n",
       "      <td>0.537545</td>\n",
       "      <td>0.847263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_multi_nb</th>\n",
       "      <td>0.953466</td>\n",
       "      <td>0.955306</td>\n",
       "      <td>0.770475</td>\n",
       "      <td>0.869519</td>\n",
       "      <td>0.822721</td>\n",
       "      <td>9.681893e-01</td>\n",
       "      <td>0.892345</td>\n",
       "      <td>0.911727</td>\n",
       "      <td>0.646348</td>\n",
       "      <td>0.816198</td>\n",
       "      <td>0.681379</td>\n",
       "      <td>1.440893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_multi_nb</th>\n",
       "      <td>0.958344</td>\n",
       "      <td>0.958733</td>\n",
       "      <td>0.786932</td>\n",
       "      <td>0.880701</td>\n",
       "      <td>0.825531</td>\n",
       "      <td>5.083924e-01</td>\n",
       "      <td>0.881971</td>\n",
       "      <td>0.900650</td>\n",
       "      <td>0.617374</td>\n",
       "      <td>0.806316</td>\n",
       "      <td>0.630341</td>\n",
       "      <td>0.870485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_multi_nb</th>\n",
       "      <td>0.958260</td>\n",
       "      <td>0.958508</td>\n",
       "      <td>0.785920</td>\n",
       "      <td>0.879890</td>\n",
       "      <td>0.825136</td>\n",
       "      <td>5.068162e-01</td>\n",
       "      <td>0.879233</td>\n",
       "      <td>0.898900</td>\n",
       "      <td>0.602618</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.883116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_multi_nb</th>\n",
       "      <td>0.967296</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.807223</td>\n",
       "      <td>0.888954</td>\n",
       "      <td>0.861842</td>\n",
       "      <td>9.961314e-01</td>\n",
       "      <td>0.908515</td>\n",
       "      <td>0.927266</td>\n",
       "      <td>0.663162</td>\n",
       "      <td>0.828330</td>\n",
       "      <td>0.695499</td>\n",
       "      <td>1.530753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_multi_nb</th>\n",
       "      <td>0.963506</td>\n",
       "      <td>0.964980</td>\n",
       "      <td>0.796566</td>\n",
       "      <td>0.885615</td>\n",
       "      <td>0.840689</td>\n",
       "      <td>5.546042e-01</td>\n",
       "      <td>0.898705</td>\n",
       "      <td>0.918027</td>\n",
       "      <td>0.643388</td>\n",
       "      <td>0.819352</td>\n",
       "      <td>0.661339</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_multi_nb</th>\n",
       "      <td>0.963435</td>\n",
       "      <td>0.964794</td>\n",
       "      <td>0.798084</td>\n",
       "      <td>0.886530</td>\n",
       "      <td>0.842361</td>\n",
       "      <td>5.510565e-01</td>\n",
       "      <td>0.897360</td>\n",
       "      <td>0.917312</td>\n",
       "      <td>0.630741</td>\n",
       "      <td>0.815192</td>\n",
       "      <td>0.648823</td>\n",
       "      <td>0.918122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_multi_nb_tfidf</th>\n",
       "      <td>0.987696</td>\n",
       "      <td>0.989596</td>\n",
       "      <td>0.876799</td>\n",
       "      <td>0.940092</td>\n",
       "      <td>0.877505</td>\n",
       "      <td>1.533512e-01</td>\n",
       "      <td>0.860457</td>\n",
       "      <td>0.884927</td>\n",
       "      <td>0.594253</td>\n",
       "      <td>0.804365</td>\n",
       "      <td>0.583154</td>\n",
       "      <td>0.573417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_multi_nb_tfidf</th>\n",
       "      <td>0.980995</td>\n",
       "      <td>0.982917</td>\n",
       "      <td>0.846985</td>\n",
       "      <td>0.922912</td>\n",
       "      <td>0.822721</td>\n",
       "      <td>1.867390e-01</td>\n",
       "      <td>0.835399</td>\n",
       "      <td>0.859145</td>\n",
       "      <td>0.554557</td>\n",
       "      <td>0.783373</td>\n",
       "      <td>0.535528</td>\n",
       "      <td>0.602590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_multi_nb_tfidf</th>\n",
       "      <td>0.981593</td>\n",
       "      <td>0.983405</td>\n",
       "      <td>0.848811</td>\n",
       "      <td>0.923755</td>\n",
       "      <td>0.826850</td>\n",
       "      <td>1.842812e-01</td>\n",
       "      <td>0.835191</td>\n",
       "      <td>0.859236</td>\n",
       "      <td>0.549541</td>\n",
       "      <td>0.782962</td>\n",
       "      <td>0.531930</td>\n",
       "      <td>0.603279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_multi_nb_tfidf</th>\n",
       "      <td>0.975062</td>\n",
       "      <td>0.974202</td>\n",
       "      <td>0.827289</td>\n",
       "      <td>0.905964</td>\n",
       "      <td>0.787511</td>\n",
       "      <td>2.592868e-01</td>\n",
       "      <td>0.907445</td>\n",
       "      <td>0.924123</td>\n",
       "      <td>0.577492</td>\n",
       "      <td>0.797846</td>\n",
       "      <td>0.541086</td>\n",
       "      <td>0.418215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_multi_nb_tfidf</th>\n",
       "      <td>0.982571</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.904250</td>\n",
       "      <td>0.768044</td>\n",
       "      <td>2.502152e-01</td>\n",
       "      <td>0.887011</td>\n",
       "      <td>0.905157</td>\n",
       "      <td>0.521972</td>\n",
       "      <td>0.770780</td>\n",
       "      <td>0.483489</td>\n",
       "      <td>0.461860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_multi_nb_tfidf</th>\n",
       "      <td>0.971897</td>\n",
       "      <td>0.971358</td>\n",
       "      <td>0.766889</td>\n",
       "      <td>0.877232</td>\n",
       "      <td>0.704708</td>\n",
       "      <td>2.921647e-01</td>\n",
       "      <td>0.885521</td>\n",
       "      <td>0.902983</td>\n",
       "      <td>0.509576</td>\n",
       "      <td>0.765919</td>\n",
       "      <td>0.475411</td>\n",
       "      <td>0.465258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_multi_nb_tfidf</th>\n",
       "      <td>0.982879</td>\n",
       "      <td>0.981614</td>\n",
       "      <td>0.868290</td>\n",
       "      <td>0.927249</td>\n",
       "      <td>0.847072</td>\n",
       "      <td>2.198836e-01</td>\n",
       "      <td>0.919782</td>\n",
       "      <td>0.936119</td>\n",
       "      <td>0.610337</td>\n",
       "      <td>0.815726</td>\n",
       "      <td>0.576222</td>\n",
       "      <td>0.389288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_multi_nb_tfidf</th>\n",
       "      <td>0.988981</td>\n",
       "      <td>0.987788</td>\n",
       "      <td>0.880290</td>\n",
       "      <td>0.933838</td>\n",
       "      <td>0.844041</td>\n",
       "      <td>2.055390e-01</td>\n",
       "      <td>0.903062</td>\n",
       "      <td>0.920809</td>\n",
       "      <td>0.563693</td>\n",
       "      <td>0.792669</td>\n",
       "      <td>0.523839</td>\n",
       "      <td>0.429720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_multi_nb_tfidf</th>\n",
       "      <td>0.974858</td>\n",
       "      <td>0.975142</td>\n",
       "      <td>0.789251</td>\n",
       "      <td>0.888772</td>\n",
       "      <td>0.735995</td>\n",
       "      <td>2.709453e-01</td>\n",
       "      <td>0.903034</td>\n",
       "      <td>0.921096</td>\n",
       "      <td>0.552174</td>\n",
       "      <td>0.786357</td>\n",
       "      <td>0.513149</td>\n",
       "      <td>0.430855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_logReg_OVR</th>\n",
       "      <td>0.992443</td>\n",
       "      <td>0.994127</td>\n",
       "      <td>0.896968</td>\n",
       "      <td>0.951447</td>\n",
       "      <td>0.890319</td>\n",
       "      <td>1.187258e-01</td>\n",
       "      <td>0.832299</td>\n",
       "      <td>0.867119</td>\n",
       "      <td>0.575556</td>\n",
       "      <td>0.794453</td>\n",
       "      <td>0.568170</td>\n",
       "      <td>0.830535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_logReg_OVR</th>\n",
       "      <td>0.989955</td>\n",
       "      <td>0.991605</td>\n",
       "      <td>0.878649</td>\n",
       "      <td>0.941791</td>\n",
       "      <td>0.868454</td>\n",
       "      <td>1.311164e-01</td>\n",
       "      <td>0.778959</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.558758</td>\n",
       "      <td>0.781722</td>\n",
       "      <td>0.552303</td>\n",
       "      <td>1.428392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_logReg_OVR</th>\n",
       "      <td>0.990376</td>\n",
       "      <td>0.991975</td>\n",
       "      <td>0.879817</td>\n",
       "      <td>0.942403</td>\n",
       "      <td>0.870181</td>\n",
       "      <td>1.286402e-01</td>\n",
       "      <td>0.779498</td>\n",
       "      <td>0.810568</td>\n",
       "      <td>0.556611</td>\n",
       "      <td>0.781875</td>\n",
       "      <td>0.548524</td>\n",
       "      <td>1.415894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_logReg_OVR</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999223</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>2.968781e-02</td>\n",
       "      <td>0.866202</td>\n",
       "      <td>0.888274</td>\n",
       "      <td>0.604816</td>\n",
       "      <td>0.809760</td>\n",
       "      <td>0.593143</td>\n",
       "      <td>0.691427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_logReg_OVR</th>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>0.993470</td>\n",
       "      <td>0.996306</td>\n",
       "      <td>0.990920</td>\n",
       "      <td>5.431313e-02</td>\n",
       "      <td>0.841773</td>\n",
       "      <td>0.864091</td>\n",
       "      <td>0.578787</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.567609</td>\n",
       "      <td>0.773831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_logReg_OVR</th>\n",
       "      <td>0.999533</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.989750</td>\n",
       "      <td>0.972895</td>\n",
       "      <td>1.084521e-01</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.884867</td>\n",
       "      <td>0.577149</td>\n",
       "      <td>0.798613</td>\n",
       "      <td>0.557472</td>\n",
       "      <td>0.531892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_logReg_OVR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>1.646652e-02</td>\n",
       "      <td>0.890897</td>\n",
       "      <td>0.911522</td>\n",
       "      <td>0.633926</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>0.619404</td>\n",
       "      <td>0.586487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_logReg_OVR</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.998301</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>0.997367</td>\n",
       "      <td>4.452684e-02</td>\n",
       "      <td>0.881660</td>\n",
       "      <td>0.902915</td>\n",
       "      <td>0.602271</td>\n",
       "      <td>0.811410</td>\n",
       "      <td>0.584451</td>\n",
       "      <td>0.553708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_logReg_OVR</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>2.593149e-02</td>\n",
       "      <td>0.869684</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.598142</td>\n",
       "      <td>0.810461</td>\n",
       "      <td>0.581910</td>\n",
       "      <td>0.680412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_logReg_OVR_tfidf</th>\n",
       "      <td>0.994450</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>0.957696</td>\n",
       "      <td>0.907299</td>\n",
       "      <td>9.730397e-02</td>\n",
       "      <td>0.838943</td>\n",
       "      <td>0.870102</td>\n",
       "      <td>0.574249</td>\n",
       "      <td>0.792057</td>\n",
       "      <td>0.574313</td>\n",
       "      <td>1.359967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_logReg_OVR_tfidf</th>\n",
       "      <td>0.987107</td>\n",
       "      <td>0.988798</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.939617</td>\n",
       "      <td>0.861810</td>\n",
       "      <td>1.454671e-01</td>\n",
       "      <td>0.801728</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.560520</td>\n",
       "      <td>0.782189</td>\n",
       "      <td>0.558617</td>\n",
       "      <td>1.201901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_logReg_OVR_tfidf</th>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.990639</td>\n",
       "      <td>0.877780</td>\n",
       "      <td>0.940804</td>\n",
       "      <td>0.864213</td>\n",
       "      <td>1.382628e-01</td>\n",
       "      <td>0.798417</td>\n",
       "      <td>0.828940</td>\n",
       "      <td>0.554942</td>\n",
       "      <td>0.779215</td>\n",
       "      <td>0.552923</td>\n",
       "      <td>1.297615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.154375e-08</td>\n",
       "      <td>0.885570</td>\n",
       "      <td>0.897838</td>\n",
       "      <td>0.600801</td>\n",
       "      <td>0.807817</td>\n",
       "      <td>0.582407</td>\n",
       "      <td>3.520746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.541925e-07</td>\n",
       "      <td>0.875868</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>0.583867</td>\n",
       "      <td>0.800570</td>\n",
       "      <td>0.557780</td>\n",
       "      <td>3.382384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.262795e-07</td>\n",
       "      <td>0.871097</td>\n",
       "      <td>0.878811</td>\n",
       "      <td>0.581634</td>\n",
       "      <td>0.800032</td>\n",
       "      <td>0.556447</td>\n",
       "      <td>3.700127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.823713e-08</td>\n",
       "      <td>0.900583</td>\n",
       "      <td>0.910300</td>\n",
       "      <td>0.640711</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.622211</td>\n",
       "      <td>3.223883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.416823e-07</td>\n",
       "      <td>0.875123</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.609035</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.595278</td>\n",
       "      <td>3.838801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.096993e-08</td>\n",
       "      <td>0.874652</td>\n",
       "      <td>0.887361</td>\n",
       "      <td>0.600958</td>\n",
       "      <td>0.809744</td>\n",
       "      <td>0.586300</td>\n",
       "      <td>3.820418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_RandomForest</th>\n",
       "      <td>0.993276</td>\n",
       "      <td>0.994204</td>\n",
       "      <td>0.921366</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.915686</td>\n",
       "      <td>1.508815e-01</td>\n",
       "      <td>0.869477</td>\n",
       "      <td>0.894690</td>\n",
       "      <td>0.579380</td>\n",
       "      <td>0.798875</td>\n",
       "      <td>0.566014</td>\n",
       "      <td>0.696638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_RandomForest</th>\n",
       "      <td>0.982941</td>\n",
       "      <td>0.983933</td>\n",
       "      <td>0.878397</td>\n",
       "      <td>0.942080</td>\n",
       "      <td>0.867798</td>\n",
       "      <td>1.982347e-01</td>\n",
       "      <td>0.826535</td>\n",
       "      <td>0.854993</td>\n",
       "      <td>0.552828</td>\n",
       "      <td>0.777634</td>\n",
       "      <td>0.549618</td>\n",
       "      <td>0.899718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_RandomForest</th>\n",
       "      <td>0.983478</td>\n",
       "      <td>0.984382</td>\n",
       "      <td>0.880465</td>\n",
       "      <td>0.943036</td>\n",
       "      <td>0.869814</td>\n",
       "      <td>1.974852e-01</td>\n",
       "      <td>0.825524</td>\n",
       "      <td>0.854907</td>\n",
       "      <td>0.550691</td>\n",
       "      <td>0.776415</td>\n",
       "      <td>0.546020</td>\n",
       "      <td>0.929271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.234378e-01</td>\n",
       "      <td>0.832727</td>\n",
       "      <td>0.854143</td>\n",
       "      <td>0.416180</td>\n",
       "      <td>0.724176</td>\n",
       "      <td>0.405863</td>\n",
       "      <td>0.602035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_RandomForest</th>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.998791</td>\n",
       "      <td>0.996377</td>\n",
       "      <td>1.446901e-01</td>\n",
       "      <td>0.779751</td>\n",
       "      <td>0.802221</td>\n",
       "      <td>0.470990</td>\n",
       "      <td>0.741684</td>\n",
       "      <td>0.453563</td>\n",
       "      <td>0.644454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_RandomForest</th>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.997672</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>1.465335e-01</td>\n",
       "      <td>0.766117</td>\n",
       "      <td>0.787175</td>\n",
       "      <td>0.456280</td>\n",
       "      <td>0.732688</td>\n",
       "      <td>0.443634</td>\n",
       "      <td>0.686401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.183898e-01</td>\n",
       "      <td>0.851205</td>\n",
       "      <td>0.872286</td>\n",
       "      <td>0.459656</td>\n",
       "      <td>0.740987</td>\n",
       "      <td>0.436730</td>\n",
       "      <td>0.579194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_RandomForest</th>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>1.394258e-01</td>\n",
       "      <td>0.798914</td>\n",
       "      <td>0.821530</td>\n",
       "      <td>0.502062</td>\n",
       "      <td>0.755432</td>\n",
       "      <td>0.486298</td>\n",
       "      <td>0.626445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_RandomForest</th>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>1.413841e-01</td>\n",
       "      <td>0.795659</td>\n",
       "      <td>0.815066</td>\n",
       "      <td>0.492848</td>\n",
       "      <td>0.752146</td>\n",
       "      <td>0.476423</td>\n",
       "      <td>0.600333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_RandomForest_tfidf</th>\n",
       "      <td>0.994381</td>\n",
       "      <td>0.995066</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.965845</td>\n",
       "      <td>0.921058</td>\n",
       "      <td>1.430722e-01</td>\n",
       "      <td>0.878849</td>\n",
       "      <td>0.901376</td>\n",
       "      <td>0.574327</td>\n",
       "      <td>0.798245</td>\n",
       "      <td>0.551378</td>\n",
       "      <td>0.544046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_RandomForest_tfidf</th>\n",
       "      <td>0.985240</td>\n",
       "      <td>0.986139</td>\n",
       "      <td>0.882200</td>\n",
       "      <td>0.944066</td>\n",
       "      <td>0.871001</td>\n",
       "      <td>1.900164e-01</td>\n",
       "      <td>0.835058</td>\n",
       "      <td>0.858968</td>\n",
       "      <td>0.550623</td>\n",
       "      <td>0.779998</td>\n",
       "      <td>0.536194</td>\n",
       "      <td>0.735740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_RandomForest_tfidf</th>\n",
       "      <td>0.985762</td>\n",
       "      <td>0.986587</td>\n",
       "      <td>0.883416</td>\n",
       "      <td>0.944615</td>\n",
       "      <td>0.872667</td>\n",
       "      <td>1.888413e-01</td>\n",
       "      <td>0.835061</td>\n",
       "      <td>0.859028</td>\n",
       "      <td>0.554578</td>\n",
       "      <td>0.781995</td>\n",
       "      <td>0.539366</td>\n",
       "      <td>0.757427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_RandomForest_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.180192e-01</td>\n",
       "      <td>0.855303</td>\n",
       "      <td>0.877119</td>\n",
       "      <td>0.428633</td>\n",
       "      <td>0.728405</td>\n",
       "      <td>0.414498</td>\n",
       "      <td>0.560142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_RandomForest_tfidf</th>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.998791</td>\n",
       "      <td>0.996377</td>\n",
       "      <td>1.274129e-01</td>\n",
       "      <td>0.797105</td>\n",
       "      <td>0.816319</td>\n",
       "      <td>0.458710</td>\n",
       "      <td>0.740304</td>\n",
       "      <td>0.438331</td>\n",
       "      <td>0.629900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_RandomForest_tfidf</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.997672</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>1.285359e-01</td>\n",
       "      <td>0.785567</td>\n",
       "      <td>0.806099</td>\n",
       "      <td>0.447037</td>\n",
       "      <td>0.735197</td>\n",
       "      <td>0.428314</td>\n",
       "      <td>0.661740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_RandomForest_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.147608e-01</td>\n",
       "      <td>0.874043</td>\n",
       "      <td>0.895497</td>\n",
       "      <td>0.459406</td>\n",
       "      <td>0.742532</td>\n",
       "      <td>0.437903</td>\n",
       "      <td>0.503530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_RandomForest_tfidf</th>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>1.227593e-01</td>\n",
       "      <td>0.817692</td>\n",
       "      <td>0.838524</td>\n",
       "      <td>0.499606</td>\n",
       "      <td>0.757760</td>\n",
       "      <td>0.474962</td>\n",
       "      <td>0.588319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_RandomForest_tfidf</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>1.244664e-01</td>\n",
       "      <td>0.817580</td>\n",
       "      <td>0.836734</td>\n",
       "      <td>0.491361</td>\n",
       "      <td>0.756146</td>\n",
       "      <td>0.467140</td>\n",
       "      <td>0.572485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ROC AUC Macro Train  \\\n",
       "alpha_title_multi_nb                             0.959946   \n",
       "stem_title_multi_nb                              0.976582   \n",
       "lemma_title_multi_nb                             0.977258   \n",
       "alpha_review_multi_nb                            0.953466   \n",
       "stem_review_multi_nb                             0.958344   \n",
       "lemma_review_multi_nb                            0.958260   \n",
       "alpha_combination_multi_nb                       0.967296   \n",
       "stem_combination_multi_nb                        0.963506   \n",
       "lemma_combination_multi_nb                       0.963435   \n",
       "alpha_title_multi_nb_tfidf                       0.987696   \n",
       "stem_title_multi_nb_tfidf                        0.980995   \n",
       "lemma_title_multi_nb_tfidf                       0.981593   \n",
       "alpha_review_multi_nb_tfidf                      0.975062   \n",
       "stem_review_multi_nb_tfidf                       0.982571   \n",
       "lemma_review_multi_nb_tfidf                      0.971897   \n",
       "alpha_combination_multi_nb_tfidf                 0.982879   \n",
       "stem_combination_multi_nb_tfidf                  0.988981   \n",
       "lemma_combination_multi_nb_tfidf                 0.974858   \n",
       "alpha_title_logReg_OVR                           0.992443   \n",
       "stem_title_logReg_OVR                            0.989955   \n",
       "lemma_title_logReg_OVR                           0.990376   \n",
       "alpha_review_logReg_OVR                          0.999989   \n",
       "stem_review_logReg_OVR                           0.999909   \n",
       "lemma_review_logReg_OVR                          0.999533   \n",
       "alpha_combination_logReg_OVR                     1.000000   \n",
       "stem_combination_logReg_OVR                      0.999991   \n",
       "lemma_combination_logReg_OVR                     0.999999   \n",
       "alpha_title_logReg_OVR_tfidf                     0.994450   \n",
       "stem_title_logReg_OVR_tfidf                      0.987107   \n",
       "lemma_title_logReg_OVR_tfidf                     0.988742   \n",
       "alpha_review_logReg_OVR_tfidf                    1.000000   \n",
       "stem_review_logReg_OVR_tfidf                     1.000000   \n",
       "lemma_review_logReg_OVR_tfidf                    1.000000   \n",
       "alpha_combination_logReg_OVR_tfidf               1.000000   \n",
       "stem_combination_logReg_OVR_tfidf                1.000000   \n",
       "lemma_combination_logReg_OVR_tfidf               1.000000   \n",
       "alpha_title_RandomForest                         0.993276   \n",
       "stem_title_RandomForest                          0.982941   \n",
       "lemma_title_RandomForest                         0.983478   \n",
       "alpha_review_RandomForest                        1.000000   \n",
       "stem_review_RandomForest                         0.999806   \n",
       "lemma_review_RandomForest                        0.999767   \n",
       "alpha_combination_RandomForest                   1.000000   \n",
       "stem_combination_RandomForest                    0.999937   \n",
       "lemma_combination_RandomForest                   0.999949   \n",
       "alpha_title_RandomForest_tfidf                   0.994381   \n",
       "stem_title_RandomForest_tfidf                    0.985240   \n",
       "lemma_title_RandomForest_tfidf                   0.985762   \n",
       "alpha_review_RandomForest_tfidf                  1.000000   \n",
       "stem_review_RandomForest_tfidf                   0.999861   \n",
       "lemma_review_RandomForest_tfidf                  0.999881   \n",
       "alpha_combination_RandomForest_tfidf             1.000000   \n",
       "stem_combination_RandomForest_tfidf              0.999959   \n",
       "lemma_combination_RandomForest_tfidf             0.999967   \n",
       "\n",
       "                                      ROC AUC Weighted Train  F1 Macro Train  \\\n",
       "alpha_title_multi_nb                                0.963244        0.787137   \n",
       "stem_title_multi_nb                                 0.978413        0.830715   \n",
       "lemma_title_multi_nb                                0.978986        0.831715   \n",
       "alpha_review_multi_nb                               0.955306        0.770475   \n",
       "stem_review_multi_nb                                0.958733        0.786932   \n",
       "lemma_review_multi_nb                               0.958508        0.785920   \n",
       "alpha_combination_multi_nb                          0.968000        0.807223   \n",
       "stem_combination_multi_nb                           0.964980        0.796566   \n",
       "lemma_combination_multi_nb                          0.964794        0.798084   \n",
       "alpha_title_multi_nb_tfidf                          0.989596        0.876799   \n",
       "stem_title_multi_nb_tfidf                           0.982917        0.846985   \n",
       "lemma_title_multi_nb_tfidf                          0.983405        0.848811   \n",
       "alpha_review_multi_nb_tfidf                         0.974202        0.827289   \n",
       "stem_review_multi_nb_tfidf                          0.981100        0.822775   \n",
       "lemma_review_multi_nb_tfidf                         0.971358        0.766889   \n",
       "alpha_combination_multi_nb_tfidf                    0.981614        0.868290   \n",
       "stem_combination_multi_nb_tfidf                     0.987788        0.880290   \n",
       "lemma_combination_multi_nb_tfidf                    0.975142        0.789251   \n",
       "alpha_title_logReg_OVR                              0.994127        0.896968   \n",
       "stem_title_logReg_OVR                               0.991605        0.878649   \n",
       "lemma_title_logReg_OVR                              0.991975        0.879817   \n",
       "alpha_review_logReg_OVR                             0.999989        0.999223   \n",
       "stem_review_logReg_OVR                              0.999905        0.993470   \n",
       "lemma_review_logReg_OVR                             0.999511        0.981749   \n",
       "alpha_combination_logReg_OVR                        1.000000        0.999803   \n",
       "stem_combination_logReg_OVR                         0.999991        0.998301   \n",
       "lemma_combination_logReg_OVR                        1.000000        0.999311   \n",
       "alpha_title_logReg_OVR_tfidf                        0.995717        0.910283   \n",
       "stem_title_logReg_OVR_tfidf                         0.988798        0.875537   \n",
       "lemma_title_logReg_OVR_tfidf                        0.990639        0.877780   \n",
       "alpha_review_logReg_OVR_tfidf                       1.000000        1.000000   \n",
       "stem_review_logReg_OVR_tfidf                        1.000000        1.000000   \n",
       "lemma_review_logReg_OVR_tfidf                       1.000000        1.000000   \n",
       "alpha_combination_logReg_OVR_tfidf                  1.000000        1.000000   \n",
       "stem_combination_logReg_OVR_tfidf                   1.000000        1.000000   \n",
       "lemma_combination_logReg_OVR_tfidf                  1.000000        1.000000   \n",
       "alpha_title_RandomForest                            0.994204        0.921366   \n",
       "stem_title_RandomForest                             0.983933        0.878397   \n",
       "lemma_title_RandomForest                            0.984382        0.880465   \n",
       "alpha_review_RandomForest                           1.000000        1.000000   \n",
       "stem_review_RandomForest                            0.999895        0.997922   \n",
       "lemma_review_RandomForest                           0.999861        0.997672   \n",
       "alpha_combination_RandomForest                      1.000000        1.000000   \n",
       "stem_combination_RandomForest                       0.999975        0.998780   \n",
       "lemma_combination_RandomForest                      0.999980        0.998780   \n",
       "alpha_title_RandomForest_tfidf                      0.995066        0.925349   \n",
       "stem_title_RandomForest_tfidf                       0.986139        0.882200   \n",
       "lemma_title_RandomForest_tfidf                      0.986587        0.883416   \n",
       "alpha_review_RandomForest_tfidf                     1.000000        1.000000   \n",
       "stem_review_RandomForest_tfidf                      0.999922        0.997922   \n",
       "lemma_review_RandomForest_tfidf                     0.999929        0.997672   \n",
       "alpha_combination_RandomForest_tfidf                1.000000        1.000000   \n",
       "stem_combination_RandomForest_tfidf                 0.999983        0.998780   \n",
       "lemma_combination_RandomForest_tfidf                0.999987        0.998780   \n",
       "\n",
       "                                      F1 Weighted Train  \\\n",
       "alpha_title_multi_nb                           0.889634   \n",
       "stem_title_multi_nb                            0.913079   \n",
       "lemma_title_multi_nb                           0.913593   \n",
       "alpha_review_multi_nb                          0.869519   \n",
       "stem_review_multi_nb                           0.880701   \n",
       "lemma_review_multi_nb                          0.879890   \n",
       "alpha_combination_multi_nb                     0.888954   \n",
       "stem_combination_multi_nb                      0.885615   \n",
       "lemma_combination_multi_nb                     0.886530   \n",
       "alpha_title_multi_nb_tfidf                     0.940092   \n",
       "stem_title_multi_nb_tfidf                      0.922912   \n",
       "lemma_title_multi_nb_tfidf                     0.923755   \n",
       "alpha_review_multi_nb_tfidf                    0.905964   \n",
       "stem_review_multi_nb_tfidf                     0.904250   \n",
       "lemma_review_multi_nb_tfidf                    0.877232   \n",
       "alpha_combination_multi_nb_tfidf               0.927249   \n",
       "stem_combination_multi_nb_tfidf                0.933838   \n",
       "lemma_combination_multi_nb_tfidf               0.888772   \n",
       "alpha_title_logReg_OVR                         0.951447   \n",
       "stem_title_logReg_OVR                          0.941791   \n",
       "lemma_title_logReg_OVR                         0.942403   \n",
       "alpha_review_logReg_OVR                        0.999555   \n",
       "stem_review_logReg_OVR                         0.996306   \n",
       "lemma_review_logReg_OVR                        0.989750   \n",
       "alpha_combination_logReg_OVR                   0.999873   \n",
       "stem_combination_logReg_OVR                    0.998982   \n",
       "lemma_combination_logReg_OVR                   0.999555   \n",
       "alpha_title_logReg_OVR_tfidf                   0.957696   \n",
       "stem_title_logReg_OVR_tfidf                    0.939617   \n",
       "lemma_title_logReg_OVR_tfidf                   0.940804   \n",
       "alpha_review_logReg_OVR_tfidf                  1.000000   \n",
       "stem_review_logReg_OVR_tfidf                   1.000000   \n",
       "lemma_review_logReg_OVR_tfidf                  1.000000   \n",
       "alpha_combination_logReg_OVR_tfidf             1.000000   \n",
       "stem_combination_logReg_OVR_tfidf              1.000000   \n",
       "lemma_combination_logReg_OVR_tfidf             1.000000   \n",
       "alpha_title_RandomForest                       0.963544   \n",
       "stem_title_RandomForest                        0.942080   \n",
       "lemma_title_RandomForest                       0.943036   \n",
       "alpha_review_RandomForest                      1.000000   \n",
       "stem_review_RandomForest                       0.998791   \n",
       "lemma_review_RandomForest                      0.998664   \n",
       "alpha_combination_RandomForest                 1.000000   \n",
       "stem_combination_RandomForest                  0.999300   \n",
       "lemma_combination_RandomForest                 0.999300   \n",
       "alpha_title_RandomForest_tfidf                 0.965845   \n",
       "stem_title_RandomForest_tfidf                  0.944066   \n",
       "lemma_title_RandomForest_tfidf                 0.944615   \n",
       "alpha_review_RandomForest_tfidf                1.000000   \n",
       "stem_review_RandomForest_tfidf                 0.998791   \n",
       "lemma_review_RandomForest_tfidf                0.998664   \n",
       "alpha_combination_RandomForest_tfidf           1.000000   \n",
       "stem_combination_RandomForest_tfidf            0.999300   \n",
       "lemma_combination_RandomForest_tfidf           0.999300   \n",
       "\n",
       "                                      Balanced Accuracy Score Train  \\\n",
       "alpha_title_multi_nb                                       0.809898   \n",
       "stem_title_multi_nb                                        0.817315   \n",
       "lemma_title_multi_nb                                       0.820252   \n",
       "alpha_review_multi_nb                                      0.822721   \n",
       "stem_review_multi_nb                                       0.825531   \n",
       "lemma_review_multi_nb                                      0.825136   \n",
       "alpha_combination_multi_nb                                 0.861842   \n",
       "stem_combination_multi_nb                                  0.840689   \n",
       "lemma_combination_multi_nb                                 0.842361   \n",
       "alpha_title_multi_nb_tfidf                                 0.877505   \n",
       "stem_title_multi_nb_tfidf                                  0.822721   \n",
       "lemma_title_multi_nb_tfidf                                 0.826850   \n",
       "alpha_review_multi_nb_tfidf                                0.787511   \n",
       "stem_review_multi_nb_tfidf                                 0.768044   \n",
       "lemma_review_multi_nb_tfidf                                0.704708   \n",
       "alpha_combination_multi_nb_tfidf                           0.847072   \n",
       "stem_combination_multi_nb_tfidf                            0.844041   \n",
       "lemma_combination_multi_nb_tfidf                           0.735995   \n",
       "alpha_title_logReg_OVR                                     0.890319   \n",
       "stem_title_logReg_OVR                                      0.868454   \n",
       "lemma_title_logReg_OVR                                     0.870181   \n",
       "alpha_review_logReg_OVR                                    0.998816   \n",
       "stem_review_logReg_OVR                                     0.990920   \n",
       "lemma_review_logReg_OVR                                    0.972895   \n",
       "alpha_combination_logReg_OVR                               0.999662   \n",
       "stem_combination_logReg_OVR                                0.997367   \n",
       "lemma_combination_logReg_OVR                               0.998816   \n",
       "alpha_title_logReg_OVR_tfidf                               0.907299   \n",
       "stem_title_logReg_OVR_tfidf                                0.861810   \n",
       "lemma_title_logReg_OVR_tfidf                               0.864213   \n",
       "alpha_review_logReg_OVR_tfidf                              1.000000   \n",
       "stem_review_logReg_OVR_tfidf                               1.000000   \n",
       "lemma_review_logReg_OVR_tfidf                              1.000000   \n",
       "alpha_combination_logReg_OVR_tfidf                         1.000000   \n",
       "stem_combination_logReg_OVR_tfidf                          1.000000   \n",
       "lemma_combination_logReg_OVR_tfidf                         1.000000   \n",
       "alpha_title_RandomForest                                   0.915686   \n",
       "stem_title_RandomForest                                    0.867798   \n",
       "lemma_title_RandomForest                                   0.869814   \n",
       "alpha_review_RandomForest                                  1.000000   \n",
       "stem_review_RandomForest                                   0.996377   \n",
       "lemma_review_RandomForest                                  0.996249   \n",
       "alpha_combination_RandomForest                             1.000000   \n",
       "stem_combination_RandomForest                              0.997867   \n",
       "lemma_combination_RandomForest                             0.997867   \n",
       "alpha_title_RandomForest_tfidf                             0.921058   \n",
       "stem_title_RandomForest_tfidf                              0.871001   \n",
       "lemma_title_RandomForest_tfidf                             0.872667   \n",
       "alpha_review_RandomForest_tfidf                            1.000000   \n",
       "stem_review_RandomForest_tfidf                             0.996377   \n",
       "lemma_review_RandomForest_tfidf                            0.996249   \n",
       "alpha_combination_RandomForest_tfidf                       1.000000   \n",
       "stem_combination_RandomForest_tfidf                        0.997867   \n",
       "lemma_combination_RandomForest_tfidf                       0.997867   \n",
       "\n",
       "                                      Log Loss Train  ROC AUC Macro Test  \\\n",
       "alpha_title_multi_nb                    3.585237e-01            0.858539   \n",
       "stem_title_multi_nb                     2.156241e-01            0.818239   \n",
       "lemma_title_multi_nb                    2.144713e-01            0.817842   \n",
       "alpha_review_multi_nb                   9.681893e-01            0.892345   \n",
       "stem_review_multi_nb                    5.083924e-01            0.881971   \n",
       "lemma_review_multi_nb                   5.068162e-01            0.879233   \n",
       "alpha_combination_multi_nb              9.961314e-01            0.908515   \n",
       "stem_combination_multi_nb               5.546042e-01            0.898705   \n",
       "lemma_combination_multi_nb              5.510565e-01            0.897360   \n",
       "alpha_title_multi_nb_tfidf              1.533512e-01            0.860457   \n",
       "stem_title_multi_nb_tfidf               1.867390e-01            0.835399   \n",
       "lemma_title_multi_nb_tfidf              1.842812e-01            0.835191   \n",
       "alpha_review_multi_nb_tfidf             2.592868e-01            0.907445   \n",
       "stem_review_multi_nb_tfidf              2.502152e-01            0.887011   \n",
       "lemma_review_multi_nb_tfidf             2.921647e-01            0.885521   \n",
       "alpha_combination_multi_nb_tfidf        2.198836e-01            0.919782   \n",
       "stem_combination_multi_nb_tfidf         2.055390e-01            0.903062   \n",
       "lemma_combination_multi_nb_tfidf        2.709453e-01            0.903034   \n",
       "alpha_title_logReg_OVR                  1.187258e-01            0.832299   \n",
       "stem_title_logReg_OVR                   1.311164e-01            0.778959   \n",
       "lemma_title_logReg_OVR                  1.286402e-01            0.779498   \n",
       "alpha_review_logReg_OVR                 2.968781e-02            0.866202   \n",
       "stem_review_logReg_OVR                  5.431313e-02            0.841773   \n",
       "lemma_review_logReg_OVR                 1.084521e-01            0.863210   \n",
       "alpha_combination_logReg_OVR            1.646652e-02            0.890897   \n",
       "stem_combination_logReg_OVR             4.452684e-02            0.881660   \n",
       "lemma_combination_logReg_OVR            2.593149e-02            0.869684   \n",
       "alpha_title_logReg_OVR_tfidf            9.730397e-02            0.838943   \n",
       "stem_title_logReg_OVR_tfidf             1.454671e-01            0.801728   \n",
       "lemma_title_logReg_OVR_tfidf            1.382628e-01            0.798417   \n",
       "alpha_review_logReg_OVR_tfidf           5.154375e-08            0.885570   \n",
       "stem_review_logReg_OVR_tfidf            1.541925e-07            0.875868   \n",
       "lemma_review_logReg_OVR_tfidf           1.262795e-07            0.871097   \n",
       "alpha_combination_logReg_OVR_tfidf      3.823713e-08            0.900583   \n",
       "stem_combination_logReg_OVR_tfidf       1.416823e-07            0.875123   \n",
       "lemma_combination_logReg_OVR_tfidf      8.096993e-08            0.874652   \n",
       "alpha_title_RandomForest                1.508815e-01            0.869477   \n",
       "stem_title_RandomForest                 1.982347e-01            0.826535   \n",
       "lemma_title_RandomForest                1.974852e-01            0.825524   \n",
       "alpha_review_RandomForest               1.234378e-01            0.832727   \n",
       "stem_review_RandomForest                1.446901e-01            0.779751   \n",
       "lemma_review_RandomForest               1.465335e-01            0.766117   \n",
       "alpha_combination_RandomForest          1.183898e-01            0.851205   \n",
       "stem_combination_RandomForest           1.394258e-01            0.798914   \n",
       "lemma_combination_RandomForest          1.413841e-01            0.795659   \n",
       "alpha_title_RandomForest_tfidf          1.430722e-01            0.878849   \n",
       "stem_title_RandomForest_tfidf           1.900164e-01            0.835058   \n",
       "lemma_title_RandomForest_tfidf          1.888413e-01            0.835061   \n",
       "alpha_review_RandomForest_tfidf         1.180192e-01            0.855303   \n",
       "stem_review_RandomForest_tfidf          1.274129e-01            0.797105   \n",
       "lemma_review_RandomForest_tfidf         1.285359e-01            0.785567   \n",
       "alpha_combination_RandomForest_tfidf    1.147608e-01            0.874043   \n",
       "stem_combination_RandomForest_tfidf     1.227593e-01            0.817692   \n",
       "lemma_combination_RandomForest_tfidf    1.244664e-01            0.817580   \n",
       "\n",
       "                                      ROC AUC Weighted Test  F1 Macro Test  \\\n",
       "alpha_title_multi_nb                               0.886654       0.607603   \n",
       "stem_title_multi_nb                                0.845558       0.552984   \n",
       "lemma_title_multi_nb                               0.845740       0.549183   \n",
       "alpha_review_multi_nb                              0.911727       0.646348   \n",
       "stem_review_multi_nb                               0.900650       0.617374   \n",
       "lemma_review_multi_nb                              0.898900       0.602618   \n",
       "alpha_combination_multi_nb                         0.927266       0.663162   \n",
       "stem_combination_multi_nb                          0.918027       0.643388   \n",
       "lemma_combination_multi_nb                         0.917312       0.630741   \n",
       "alpha_title_multi_nb_tfidf                         0.884927       0.594253   \n",
       "stem_title_multi_nb_tfidf                          0.859145       0.554557   \n",
       "lemma_title_multi_nb_tfidf                         0.859236       0.549541   \n",
       "alpha_review_multi_nb_tfidf                        0.924123       0.577492   \n",
       "stem_review_multi_nb_tfidf                         0.905157       0.521972   \n",
       "lemma_review_multi_nb_tfidf                        0.902983       0.509576   \n",
       "alpha_combination_multi_nb_tfidf                   0.936119       0.610337   \n",
       "stem_combination_multi_nb_tfidf                    0.920809       0.563693   \n",
       "lemma_combination_multi_nb_tfidf                   0.921096       0.552174   \n",
       "alpha_title_logReg_OVR                             0.867119       0.575556   \n",
       "stem_title_logReg_OVR                              0.810990       0.558758   \n",
       "lemma_title_logReg_OVR                             0.810568       0.556611   \n",
       "alpha_review_logReg_OVR                            0.888274       0.604816   \n",
       "stem_review_logReg_OVR                             0.864091       0.578787   \n",
       "lemma_review_logReg_OVR                            0.884867       0.577149   \n",
       "alpha_combination_logReg_OVR                       0.911522       0.633926   \n",
       "stem_combination_logReg_OVR                        0.902915       0.602271   \n",
       "lemma_combination_logReg_OVR                       0.893727       0.598142   \n",
       "alpha_title_logReg_OVR_tfidf                       0.870102       0.574249   \n",
       "stem_title_logReg_OVR_tfidf                        0.830118       0.560520   \n",
       "lemma_title_logReg_OVR_tfidf                       0.828940       0.554942   \n",
       "alpha_review_logReg_OVR_tfidf                      0.897838       0.600801   \n",
       "stem_review_logReg_OVR_tfidf                       0.888421       0.583867   \n",
       "lemma_review_logReg_OVR_tfidf                      0.878811       0.581634   \n",
       "alpha_combination_logReg_OVR_tfidf                 0.910300       0.640711   \n",
       "stem_combination_logReg_OVR_tfidf                  0.887885       0.609035   \n",
       "lemma_combination_logReg_OVR_tfidf                 0.887361       0.600958   \n",
       "alpha_title_RandomForest                           0.894690       0.579380   \n",
       "stem_title_RandomForest                            0.854993       0.552828   \n",
       "lemma_title_RandomForest                           0.854907       0.550691   \n",
       "alpha_review_RandomForest                          0.854143       0.416180   \n",
       "stem_review_RandomForest                           0.802221       0.470990   \n",
       "lemma_review_RandomForest                          0.787175       0.456280   \n",
       "alpha_combination_RandomForest                     0.872286       0.459656   \n",
       "stem_combination_RandomForest                      0.821530       0.502062   \n",
       "lemma_combination_RandomForest                     0.815066       0.492848   \n",
       "alpha_title_RandomForest_tfidf                     0.901376       0.574327   \n",
       "stem_title_RandomForest_tfidf                      0.858968       0.550623   \n",
       "lemma_title_RandomForest_tfidf                     0.859028       0.554578   \n",
       "alpha_review_RandomForest_tfidf                    0.877119       0.428633   \n",
       "stem_review_RandomForest_tfidf                     0.816319       0.458710   \n",
       "lemma_review_RandomForest_tfidf                    0.806099       0.447037   \n",
       "alpha_combination_RandomForest_tfidf               0.895497       0.459406   \n",
       "stem_combination_RandomForest_tfidf                0.838524       0.499606   \n",
       "lemma_combination_RandomForest_tfidf               0.836734       0.491361   \n",
       "\n",
       "                                      F1 Weighted Test  \\\n",
       "alpha_title_multi_nb                          0.804344   \n",
       "stem_title_multi_nb                           0.778776   \n",
       "lemma_title_multi_nb                          0.778411   \n",
       "alpha_review_multi_nb                         0.816198   \n",
       "stem_review_multi_nb                          0.806316   \n",
       "lemma_review_multi_nb                         0.800454   \n",
       "alpha_combination_multi_nb                    0.828330   \n",
       "stem_combination_multi_nb                     0.819352   \n",
       "lemma_combination_multi_nb                    0.815192   \n",
       "alpha_title_multi_nb_tfidf                    0.804365   \n",
       "stem_title_multi_nb_tfidf                     0.783373   \n",
       "lemma_title_multi_nb_tfidf                    0.782962   \n",
       "alpha_review_multi_nb_tfidf                   0.797846   \n",
       "stem_review_multi_nb_tfidf                    0.770780   \n",
       "lemma_review_multi_nb_tfidf                   0.765919   \n",
       "alpha_combination_multi_nb_tfidf              0.815726   \n",
       "stem_combination_multi_nb_tfidf               0.792669   \n",
       "lemma_combination_multi_nb_tfidf              0.786357   \n",
       "alpha_title_logReg_OVR                        0.794453   \n",
       "stem_title_logReg_OVR                         0.781722   \n",
       "lemma_title_logReg_OVR                        0.781875   \n",
       "alpha_review_logReg_OVR                       0.809760   \n",
       "stem_review_logReg_OVR                        0.794466   \n",
       "lemma_review_logReg_OVR                       0.798613   \n",
       "alpha_combination_logReg_OVR                  0.826748   \n",
       "stem_combination_logReg_OVR                   0.811410   \n",
       "lemma_combination_logReg_OVR                  0.810461   \n",
       "alpha_title_logReg_OVR_tfidf                  0.792057   \n",
       "stem_title_logReg_OVR_tfidf                   0.782189   \n",
       "lemma_title_logReg_OVR_tfidf                  0.779215   \n",
       "alpha_review_logReg_OVR_tfidf                 0.807817   \n",
       "stem_review_logReg_OVR_tfidf                  0.800570   \n",
       "lemma_review_logReg_OVR_tfidf                 0.800032   \n",
       "alpha_combination_logReg_OVR_tfidf            0.828111   \n",
       "stem_combination_logReg_OVR_tfidf             0.812543   \n",
       "lemma_combination_logReg_OVR_tfidf            0.809744   \n",
       "alpha_title_RandomForest                      0.798875   \n",
       "stem_title_RandomForest                       0.777634   \n",
       "lemma_title_RandomForest                      0.776415   \n",
       "alpha_review_RandomForest                     0.724176   \n",
       "stem_review_RandomForest                      0.741684   \n",
       "lemma_review_RandomForest                     0.732688   \n",
       "alpha_combination_RandomForest                0.740987   \n",
       "stem_combination_RandomForest                 0.755432   \n",
       "lemma_combination_RandomForest                0.752146   \n",
       "alpha_title_RandomForest_tfidf                0.798245   \n",
       "stem_title_RandomForest_tfidf                 0.779998   \n",
       "lemma_title_RandomForest_tfidf                0.781995   \n",
       "alpha_review_RandomForest_tfidf               0.728405   \n",
       "stem_review_RandomForest_tfidf                0.740304   \n",
       "lemma_review_RandomForest_tfidf               0.735197   \n",
       "alpha_combination_RandomForest_tfidf          0.742532   \n",
       "stem_combination_RandomForest_tfidf           0.757760   \n",
       "lemma_combination_RandomForest_tfidf          0.756146   \n",
       "\n",
       "                                      Balanced Accuracy Score Test  \\\n",
       "alpha_title_multi_nb                                      0.612567   \n",
       "stem_title_multi_nb                                       0.541516   \n",
       "lemma_title_multi_nb                                      0.537545   \n",
       "alpha_review_multi_nb                                     0.681379   \n",
       "stem_review_multi_nb                                      0.630341   \n",
       "lemma_review_multi_nb                                     0.613504   \n",
       "alpha_combination_multi_nb                                0.695499   \n",
       "stem_combination_multi_nb                                 0.661339   \n",
       "lemma_combination_multi_nb                                0.648823   \n",
       "alpha_title_multi_nb_tfidf                                0.583154   \n",
       "stem_title_multi_nb_tfidf                                 0.535528   \n",
       "lemma_title_multi_nb_tfidf                                0.531930   \n",
       "alpha_review_multi_nb_tfidf                               0.541086   \n",
       "stem_review_multi_nb_tfidf                                0.483489   \n",
       "lemma_review_multi_nb_tfidf                               0.475411   \n",
       "alpha_combination_multi_nb_tfidf                          0.576222   \n",
       "stem_combination_multi_nb_tfidf                           0.523839   \n",
       "lemma_combination_multi_nb_tfidf                          0.513149   \n",
       "alpha_title_logReg_OVR                                    0.568170   \n",
       "stem_title_logReg_OVR                                     0.552303   \n",
       "lemma_title_logReg_OVR                                    0.548524   \n",
       "alpha_review_logReg_OVR                                   0.593143   \n",
       "stem_review_logReg_OVR                                    0.567609   \n",
       "lemma_review_logReg_OVR                                   0.557472   \n",
       "alpha_combination_logReg_OVR                              0.619404   \n",
       "stem_combination_logReg_OVR                               0.584451   \n",
       "lemma_combination_logReg_OVR                              0.581910   \n",
       "alpha_title_logReg_OVR_tfidf                              0.574313   \n",
       "stem_title_logReg_OVR_tfidf                               0.558617   \n",
       "lemma_title_logReg_OVR_tfidf                              0.552923   \n",
       "alpha_review_logReg_OVR_tfidf                             0.582407   \n",
       "stem_review_logReg_OVR_tfidf                              0.557780   \n",
       "lemma_review_logReg_OVR_tfidf                             0.556447   \n",
       "alpha_combination_logReg_OVR_tfidf                        0.622211   \n",
       "stem_combination_logReg_OVR_tfidf                         0.595278   \n",
       "lemma_combination_logReg_OVR_tfidf                        0.586300   \n",
       "alpha_title_RandomForest                                  0.566014   \n",
       "stem_title_RandomForest                                   0.549618   \n",
       "lemma_title_RandomForest                                  0.546020   \n",
       "alpha_review_RandomForest                                 0.405863   \n",
       "stem_review_RandomForest                                  0.453563   \n",
       "lemma_review_RandomForest                                 0.443634   \n",
       "alpha_combination_RandomForest                            0.436730   \n",
       "stem_combination_RandomForest                             0.486298   \n",
       "lemma_combination_RandomForest                            0.476423   \n",
       "alpha_title_RandomForest_tfidf                            0.551378   \n",
       "stem_title_RandomForest_tfidf                             0.536194   \n",
       "lemma_title_RandomForest_tfidf                            0.539366   \n",
       "alpha_review_RandomForest_tfidf                           0.414498   \n",
       "stem_review_RandomForest_tfidf                            0.438331   \n",
       "lemma_review_RandomForest_tfidf                           0.428314   \n",
       "alpha_combination_RandomForest_tfidf                      0.437903   \n",
       "stem_combination_RandomForest_tfidf                       0.474962   \n",
       "lemma_combination_RandomForest_tfidf                      0.467140   \n",
       "\n",
       "                                      Log Loss Test  \n",
       "alpha_title_multi_nb                       0.731238  \n",
       "stem_title_multi_nb                        0.854089  \n",
       "lemma_title_multi_nb                       0.847263  \n",
       "alpha_review_multi_nb                      1.440893  \n",
       "stem_review_multi_nb                       0.870485  \n",
       "lemma_review_multi_nb                      0.883116  \n",
       "alpha_combination_multi_nb                 1.530753  \n",
       "stem_combination_multi_nb                  0.918296  \n",
       "lemma_combination_multi_nb                 0.918122  \n",
       "alpha_title_multi_nb_tfidf                 0.573417  \n",
       "stem_title_multi_nb_tfidf                  0.602590  \n",
       "lemma_title_multi_nb_tfidf                 0.603279  \n",
       "alpha_review_multi_nb_tfidf                0.418215  \n",
       "stem_review_multi_nb_tfidf                 0.461860  \n",
       "lemma_review_multi_nb_tfidf                0.465258  \n",
       "alpha_combination_multi_nb_tfidf           0.389288  \n",
       "stem_combination_multi_nb_tfidf            0.429720  \n",
       "lemma_combination_multi_nb_tfidf           0.430855  \n",
       "alpha_title_logReg_OVR                     0.830535  \n",
       "stem_title_logReg_OVR                      1.428392  \n",
       "lemma_title_logReg_OVR                     1.415894  \n",
       "alpha_review_logReg_OVR                    0.691427  \n",
       "stem_review_logReg_OVR                     0.773831  \n",
       "lemma_review_logReg_OVR                    0.531892  \n",
       "alpha_combination_logReg_OVR               0.586487  \n",
       "stem_combination_logReg_OVR                0.553708  \n",
       "lemma_combination_logReg_OVR               0.680412  \n",
       "alpha_title_logReg_OVR_tfidf               1.359967  \n",
       "stem_title_logReg_OVR_tfidf                1.201901  \n",
       "lemma_title_logReg_OVR_tfidf               1.297615  \n",
       "alpha_review_logReg_OVR_tfidf              3.520746  \n",
       "stem_review_logReg_OVR_tfidf               3.382384  \n",
       "lemma_review_logReg_OVR_tfidf              3.700127  \n",
       "alpha_combination_logReg_OVR_tfidf         3.223883  \n",
       "stem_combination_logReg_OVR_tfidf          3.838801  \n",
       "lemma_combination_logReg_OVR_tfidf         3.820418  \n",
       "alpha_title_RandomForest                   0.696638  \n",
       "stem_title_RandomForest                    0.899718  \n",
       "lemma_title_RandomForest                   0.929271  \n",
       "alpha_review_RandomForest                  0.602035  \n",
       "stem_review_RandomForest                   0.644454  \n",
       "lemma_review_RandomForest                  0.686401  \n",
       "alpha_combination_RandomForest             0.579194  \n",
       "stem_combination_RandomForest              0.626445  \n",
       "lemma_combination_RandomForest             0.600333  \n",
       "alpha_title_RandomForest_tfidf             0.544046  \n",
       "stem_title_RandomForest_tfidf              0.735740  \n",
       "lemma_title_RandomForest_tfidf             0.757427  \n",
       "alpha_review_RandomForest_tfidf            0.560142  \n",
       "stem_review_RandomForest_tfidf             0.629900  \n",
       "lemma_review_RandomForest_tfidf            0.661740  \n",
       "alpha_combination_RandomForest_tfidf       0.503530  \n",
       "stem_combination_RandomForest_tfidf        0.588319  \n",
       "lemma_combination_RandomForest_tfidf       0.572485  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_error = pd.DataFrame(train_score, index=index_name)\n",
    "test_error = pd.DataFrame(test_score, index=index_name)\n",
    "error = pd.concat((train_error, test_error), axis=1)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Macro Train</th>\n",
       "      <th>ROC AUC Weighted Train</th>\n",
       "      <th>F1 Macro Train</th>\n",
       "      <th>F1 Weighted Train</th>\n",
       "      <th>Balanced Accuracy Score Train</th>\n",
       "      <th>Log Loss Train</th>\n",
       "      <th>ROC AUC Macro Test</th>\n",
       "      <th>ROC AUC Weighted Test</th>\n",
       "      <th>F1 Macro Test</th>\n",
       "      <th>F1 Weighted Test</th>\n",
       "      <th>Balanced Accuracy Score Test</th>\n",
       "      <th>Log Loss Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_title_multi_nb</th>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.963244</td>\n",
       "      <td>0.787137</td>\n",
       "      <td>0.889634</td>\n",
       "      <td>0.809898</td>\n",
       "      <td>0.358524</td>\n",
       "      <td>0.858539</td>\n",
       "      <td>0.886654</td>\n",
       "      <td>0.607603</td>\n",
       "      <td>0.804344</td>\n",
       "      <td>0.612567</td>\n",
       "      <td>0.731238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_multi_nb</th>\n",
       "      <td>0.976582</td>\n",
       "      <td>0.978413</td>\n",
       "      <td>0.830715</td>\n",
       "      <td>0.913079</td>\n",
       "      <td>0.817315</td>\n",
       "      <td>0.215624</td>\n",
       "      <td>0.818239</td>\n",
       "      <td>0.845558</td>\n",
       "      <td>0.552984</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.541516</td>\n",
       "      <td>0.854089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_multi_nb</th>\n",
       "      <td>0.977258</td>\n",
       "      <td>0.978986</td>\n",
       "      <td>0.831715</td>\n",
       "      <td>0.913593</td>\n",
       "      <td>0.820252</td>\n",
       "      <td>0.214471</td>\n",
       "      <td>0.817842</td>\n",
       "      <td>0.845740</td>\n",
       "      <td>0.549183</td>\n",
       "      <td>0.778411</td>\n",
       "      <td>0.537545</td>\n",
       "      <td>0.847263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_multi_nb_tfidf</th>\n",
       "      <td>0.987696</td>\n",
       "      <td>0.989596</td>\n",
       "      <td>0.876799</td>\n",
       "      <td>0.940092</td>\n",
       "      <td>0.877505</td>\n",
       "      <td>0.153351</td>\n",
       "      <td>0.860457</td>\n",
       "      <td>0.884927</td>\n",
       "      <td>0.594253</td>\n",
       "      <td>0.804365</td>\n",
       "      <td>0.583154</td>\n",
       "      <td>0.573417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_multi_nb_tfidf</th>\n",
       "      <td>0.980995</td>\n",
       "      <td>0.982917</td>\n",
       "      <td>0.846985</td>\n",
       "      <td>0.922912</td>\n",
       "      <td>0.822721</td>\n",
       "      <td>0.186739</td>\n",
       "      <td>0.835399</td>\n",
       "      <td>0.859145</td>\n",
       "      <td>0.554557</td>\n",
       "      <td>0.783373</td>\n",
       "      <td>0.535528</td>\n",
       "      <td>0.602590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_multi_nb_tfidf</th>\n",
       "      <td>0.981593</td>\n",
       "      <td>0.983405</td>\n",
       "      <td>0.848811</td>\n",
       "      <td>0.923755</td>\n",
       "      <td>0.826850</td>\n",
       "      <td>0.184281</td>\n",
       "      <td>0.835191</td>\n",
       "      <td>0.859236</td>\n",
       "      <td>0.549541</td>\n",
       "      <td>0.782962</td>\n",
       "      <td>0.531930</td>\n",
       "      <td>0.603279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_logReg_OVR</th>\n",
       "      <td>0.992443</td>\n",
       "      <td>0.994127</td>\n",
       "      <td>0.896968</td>\n",
       "      <td>0.951447</td>\n",
       "      <td>0.890319</td>\n",
       "      <td>0.118726</td>\n",
       "      <td>0.832299</td>\n",
       "      <td>0.867119</td>\n",
       "      <td>0.575556</td>\n",
       "      <td>0.794453</td>\n",
       "      <td>0.568170</td>\n",
       "      <td>0.830535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_logReg_OVR</th>\n",
       "      <td>0.989955</td>\n",
       "      <td>0.991605</td>\n",
       "      <td>0.878649</td>\n",
       "      <td>0.941791</td>\n",
       "      <td>0.868454</td>\n",
       "      <td>0.131116</td>\n",
       "      <td>0.778959</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.558758</td>\n",
       "      <td>0.781722</td>\n",
       "      <td>0.552303</td>\n",
       "      <td>1.428392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_logReg_OVR</th>\n",
       "      <td>0.990376</td>\n",
       "      <td>0.991975</td>\n",
       "      <td>0.879817</td>\n",
       "      <td>0.942403</td>\n",
       "      <td>0.870181</td>\n",
       "      <td>0.128640</td>\n",
       "      <td>0.779498</td>\n",
       "      <td>0.810568</td>\n",
       "      <td>0.556611</td>\n",
       "      <td>0.781875</td>\n",
       "      <td>0.548524</td>\n",
       "      <td>1.415894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_logReg_OVR_tfidf</th>\n",
       "      <td>0.994450</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>0.957696</td>\n",
       "      <td>0.907299</td>\n",
       "      <td>0.097304</td>\n",
       "      <td>0.838943</td>\n",
       "      <td>0.870102</td>\n",
       "      <td>0.574249</td>\n",
       "      <td>0.792057</td>\n",
       "      <td>0.574313</td>\n",
       "      <td>1.359967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_logReg_OVR_tfidf</th>\n",
       "      <td>0.987107</td>\n",
       "      <td>0.988798</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.939617</td>\n",
       "      <td>0.861810</td>\n",
       "      <td>0.145467</td>\n",
       "      <td>0.801728</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.560520</td>\n",
       "      <td>0.782189</td>\n",
       "      <td>0.558617</td>\n",
       "      <td>1.201901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_logReg_OVR_tfidf</th>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.990639</td>\n",
       "      <td>0.877780</td>\n",
       "      <td>0.940804</td>\n",
       "      <td>0.864213</td>\n",
       "      <td>0.138263</td>\n",
       "      <td>0.798417</td>\n",
       "      <td>0.828940</td>\n",
       "      <td>0.554942</td>\n",
       "      <td>0.779215</td>\n",
       "      <td>0.552923</td>\n",
       "      <td>1.297615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_RandomForest</th>\n",
       "      <td>0.993276</td>\n",
       "      <td>0.994204</td>\n",
       "      <td>0.921366</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.915686</td>\n",
       "      <td>0.150881</td>\n",
       "      <td>0.869477</td>\n",
       "      <td>0.894690</td>\n",
       "      <td>0.579380</td>\n",
       "      <td>0.798875</td>\n",
       "      <td>0.566014</td>\n",
       "      <td>0.696638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_RandomForest</th>\n",
       "      <td>0.982941</td>\n",
       "      <td>0.983933</td>\n",
       "      <td>0.878397</td>\n",
       "      <td>0.942080</td>\n",
       "      <td>0.867798</td>\n",
       "      <td>0.198235</td>\n",
       "      <td>0.826535</td>\n",
       "      <td>0.854993</td>\n",
       "      <td>0.552828</td>\n",
       "      <td>0.777634</td>\n",
       "      <td>0.549618</td>\n",
       "      <td>0.899718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_RandomForest</th>\n",
       "      <td>0.983478</td>\n",
       "      <td>0.984382</td>\n",
       "      <td>0.880465</td>\n",
       "      <td>0.943036</td>\n",
       "      <td>0.869814</td>\n",
       "      <td>0.197485</td>\n",
       "      <td>0.825524</td>\n",
       "      <td>0.854907</td>\n",
       "      <td>0.550691</td>\n",
       "      <td>0.776415</td>\n",
       "      <td>0.546020</td>\n",
       "      <td>0.929271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_title_RandomForest_tfidf</th>\n",
       "      <td>0.994381</td>\n",
       "      <td>0.995066</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.965845</td>\n",
       "      <td>0.921058</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.878849</td>\n",
       "      <td>0.901376</td>\n",
       "      <td>0.574327</td>\n",
       "      <td>0.798245</td>\n",
       "      <td>0.551378</td>\n",
       "      <td>0.544046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_title_RandomForest_tfidf</th>\n",
       "      <td>0.985240</td>\n",
       "      <td>0.986139</td>\n",
       "      <td>0.882200</td>\n",
       "      <td>0.944066</td>\n",
       "      <td>0.871001</td>\n",
       "      <td>0.190016</td>\n",
       "      <td>0.835058</td>\n",
       "      <td>0.858968</td>\n",
       "      <td>0.550623</td>\n",
       "      <td>0.779998</td>\n",
       "      <td>0.536194</td>\n",
       "      <td>0.735740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_title_RandomForest_tfidf</th>\n",
       "      <td>0.985762</td>\n",
       "      <td>0.986587</td>\n",
       "      <td>0.883416</td>\n",
       "      <td>0.944615</td>\n",
       "      <td>0.872667</td>\n",
       "      <td>0.188841</td>\n",
       "      <td>0.835061</td>\n",
       "      <td>0.859028</td>\n",
       "      <td>0.554578</td>\n",
       "      <td>0.781995</td>\n",
       "      <td>0.539366</td>\n",
       "      <td>0.757427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ROC AUC Macro Train  ROC AUC Weighted Train  \\\n",
       "alpha_title_multi_nb                       0.959946                0.963244   \n",
       "stem_title_multi_nb                        0.976582                0.978413   \n",
       "lemma_title_multi_nb                       0.977258                0.978986   \n",
       "alpha_title_multi_nb_tfidf                 0.987696                0.989596   \n",
       "stem_title_multi_nb_tfidf                  0.980995                0.982917   \n",
       "lemma_title_multi_nb_tfidf                 0.981593                0.983405   \n",
       "alpha_title_logReg_OVR                     0.992443                0.994127   \n",
       "stem_title_logReg_OVR                      0.989955                0.991605   \n",
       "lemma_title_logReg_OVR                     0.990376                0.991975   \n",
       "alpha_title_logReg_OVR_tfidf               0.994450                0.995717   \n",
       "stem_title_logReg_OVR_tfidf                0.987107                0.988798   \n",
       "lemma_title_logReg_OVR_tfidf               0.988742                0.990639   \n",
       "alpha_title_RandomForest                   0.993276                0.994204   \n",
       "stem_title_RandomForest                    0.982941                0.983933   \n",
       "lemma_title_RandomForest                   0.983478                0.984382   \n",
       "alpha_title_RandomForest_tfidf             0.994381                0.995066   \n",
       "stem_title_RandomForest_tfidf              0.985240                0.986139   \n",
       "lemma_title_RandomForest_tfidf             0.985762                0.986587   \n",
       "\n",
       "                                F1 Macro Train  F1 Weighted Train  \\\n",
       "alpha_title_multi_nb                  0.787137           0.889634   \n",
       "stem_title_multi_nb                   0.830715           0.913079   \n",
       "lemma_title_multi_nb                  0.831715           0.913593   \n",
       "alpha_title_multi_nb_tfidf            0.876799           0.940092   \n",
       "stem_title_multi_nb_tfidf             0.846985           0.922912   \n",
       "lemma_title_multi_nb_tfidf            0.848811           0.923755   \n",
       "alpha_title_logReg_OVR                0.896968           0.951447   \n",
       "stem_title_logReg_OVR                 0.878649           0.941791   \n",
       "lemma_title_logReg_OVR                0.879817           0.942403   \n",
       "alpha_title_logReg_OVR_tfidf          0.910283           0.957696   \n",
       "stem_title_logReg_OVR_tfidf           0.875537           0.939617   \n",
       "lemma_title_logReg_OVR_tfidf          0.877780           0.940804   \n",
       "alpha_title_RandomForest              0.921366           0.963544   \n",
       "stem_title_RandomForest               0.878397           0.942080   \n",
       "lemma_title_RandomForest              0.880465           0.943036   \n",
       "alpha_title_RandomForest_tfidf        0.925349           0.965845   \n",
       "stem_title_RandomForest_tfidf         0.882200           0.944066   \n",
       "lemma_title_RandomForest_tfidf        0.883416           0.944615   \n",
       "\n",
       "                                Balanced Accuracy Score Train  Log Loss Train  \\\n",
       "alpha_title_multi_nb                                 0.809898        0.358524   \n",
       "stem_title_multi_nb                                  0.817315        0.215624   \n",
       "lemma_title_multi_nb                                 0.820252        0.214471   \n",
       "alpha_title_multi_nb_tfidf                           0.877505        0.153351   \n",
       "stem_title_multi_nb_tfidf                            0.822721        0.186739   \n",
       "lemma_title_multi_nb_tfidf                           0.826850        0.184281   \n",
       "alpha_title_logReg_OVR                               0.890319        0.118726   \n",
       "stem_title_logReg_OVR                                0.868454        0.131116   \n",
       "lemma_title_logReg_OVR                               0.870181        0.128640   \n",
       "alpha_title_logReg_OVR_tfidf                         0.907299        0.097304   \n",
       "stem_title_logReg_OVR_tfidf                          0.861810        0.145467   \n",
       "lemma_title_logReg_OVR_tfidf                         0.864213        0.138263   \n",
       "alpha_title_RandomForest                             0.915686        0.150881   \n",
       "stem_title_RandomForest                              0.867798        0.198235   \n",
       "lemma_title_RandomForest                             0.869814        0.197485   \n",
       "alpha_title_RandomForest_tfidf                       0.921058        0.143072   \n",
       "stem_title_RandomForest_tfidf                        0.871001        0.190016   \n",
       "lemma_title_RandomForest_tfidf                       0.872667        0.188841   \n",
       "\n",
       "                                ROC AUC Macro Test  ROC AUC Weighted Test  \\\n",
       "alpha_title_multi_nb                      0.858539               0.886654   \n",
       "stem_title_multi_nb                       0.818239               0.845558   \n",
       "lemma_title_multi_nb                      0.817842               0.845740   \n",
       "alpha_title_multi_nb_tfidf                0.860457               0.884927   \n",
       "stem_title_multi_nb_tfidf                 0.835399               0.859145   \n",
       "lemma_title_multi_nb_tfidf                0.835191               0.859236   \n",
       "alpha_title_logReg_OVR                    0.832299               0.867119   \n",
       "stem_title_logReg_OVR                     0.778959               0.810990   \n",
       "lemma_title_logReg_OVR                    0.779498               0.810568   \n",
       "alpha_title_logReg_OVR_tfidf              0.838943               0.870102   \n",
       "stem_title_logReg_OVR_tfidf               0.801728               0.830118   \n",
       "lemma_title_logReg_OVR_tfidf              0.798417               0.828940   \n",
       "alpha_title_RandomForest                  0.869477               0.894690   \n",
       "stem_title_RandomForest                   0.826535               0.854993   \n",
       "lemma_title_RandomForest                  0.825524               0.854907   \n",
       "alpha_title_RandomForest_tfidf            0.878849               0.901376   \n",
       "stem_title_RandomForest_tfidf             0.835058               0.858968   \n",
       "lemma_title_RandomForest_tfidf            0.835061               0.859028   \n",
       "\n",
       "                                F1 Macro Test  F1 Weighted Test  \\\n",
       "alpha_title_multi_nb                 0.607603          0.804344   \n",
       "stem_title_multi_nb                  0.552984          0.778776   \n",
       "lemma_title_multi_nb                 0.549183          0.778411   \n",
       "alpha_title_multi_nb_tfidf           0.594253          0.804365   \n",
       "stem_title_multi_nb_tfidf            0.554557          0.783373   \n",
       "lemma_title_multi_nb_tfidf           0.549541          0.782962   \n",
       "alpha_title_logReg_OVR               0.575556          0.794453   \n",
       "stem_title_logReg_OVR                0.558758          0.781722   \n",
       "lemma_title_logReg_OVR               0.556611          0.781875   \n",
       "alpha_title_logReg_OVR_tfidf         0.574249          0.792057   \n",
       "stem_title_logReg_OVR_tfidf          0.560520          0.782189   \n",
       "lemma_title_logReg_OVR_tfidf         0.554942          0.779215   \n",
       "alpha_title_RandomForest             0.579380          0.798875   \n",
       "stem_title_RandomForest              0.552828          0.777634   \n",
       "lemma_title_RandomForest             0.550691          0.776415   \n",
       "alpha_title_RandomForest_tfidf       0.574327          0.798245   \n",
       "stem_title_RandomForest_tfidf        0.550623          0.779998   \n",
       "lemma_title_RandomForest_tfidf       0.554578          0.781995   \n",
       "\n",
       "                                Balanced Accuracy Score Test  Log Loss Test  \n",
       "alpha_title_multi_nb                                0.612567       0.731238  \n",
       "stem_title_multi_nb                                 0.541516       0.854089  \n",
       "lemma_title_multi_nb                                0.537545       0.847263  \n",
       "alpha_title_multi_nb_tfidf                          0.583154       0.573417  \n",
       "stem_title_multi_nb_tfidf                           0.535528       0.602590  \n",
       "lemma_title_multi_nb_tfidf                          0.531930       0.603279  \n",
       "alpha_title_logReg_OVR                              0.568170       0.830535  \n",
       "stem_title_logReg_OVR                               0.552303       1.428392  \n",
       "lemma_title_logReg_OVR                              0.548524       1.415894  \n",
       "alpha_title_logReg_OVR_tfidf                        0.574313       1.359967  \n",
       "stem_title_logReg_OVR_tfidf                         0.558617       1.201901  \n",
       "lemma_title_logReg_OVR_tfidf                        0.552923       1.297615  \n",
       "alpha_title_RandomForest                            0.566014       0.696638  \n",
       "stem_title_RandomForest                             0.549618       0.899718  \n",
       "lemma_title_RandomForest                            0.546020       0.929271  \n",
       "alpha_title_RandomForest_tfidf                      0.551378       0.544046  \n",
       "stem_title_RandomForest_tfidf                       0.536194       0.735740  \n",
       "lemma_title_RandomForest_tfidf                      0.539366       0.757427  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = [i for i in error.index if 'title' in i]\n",
    "title_error = error.loc[title]\n",
    "title_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Macro Train</th>\n",
       "      <th>ROC AUC Weighted Train</th>\n",
       "      <th>F1 Macro Train</th>\n",
       "      <th>F1 Weighted Train</th>\n",
       "      <th>Balanced Accuracy Score Train</th>\n",
       "      <th>Log Loss Train</th>\n",
       "      <th>ROC AUC Macro Test</th>\n",
       "      <th>ROC AUC Weighted Test</th>\n",
       "      <th>F1 Macro Test</th>\n",
       "      <th>F1 Weighted Test</th>\n",
       "      <th>Balanced Accuracy Score Test</th>\n",
       "      <th>Log Loss Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_review_multi_nb</th>\n",
       "      <td>0.953466</td>\n",
       "      <td>0.955306</td>\n",
       "      <td>0.770475</td>\n",
       "      <td>0.869519</td>\n",
       "      <td>0.822721</td>\n",
       "      <td>9.681893e-01</td>\n",
       "      <td>0.892345</td>\n",
       "      <td>0.911727</td>\n",
       "      <td>0.646348</td>\n",
       "      <td>0.816198</td>\n",
       "      <td>0.681379</td>\n",
       "      <td>1.440893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_multi_nb</th>\n",
       "      <td>0.958344</td>\n",
       "      <td>0.958733</td>\n",
       "      <td>0.786932</td>\n",
       "      <td>0.880701</td>\n",
       "      <td>0.825531</td>\n",
       "      <td>5.083924e-01</td>\n",
       "      <td>0.881971</td>\n",
       "      <td>0.900650</td>\n",
       "      <td>0.617374</td>\n",
       "      <td>0.806316</td>\n",
       "      <td>0.630341</td>\n",
       "      <td>0.870485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_multi_nb</th>\n",
       "      <td>0.958260</td>\n",
       "      <td>0.958508</td>\n",
       "      <td>0.785920</td>\n",
       "      <td>0.879890</td>\n",
       "      <td>0.825136</td>\n",
       "      <td>5.068162e-01</td>\n",
       "      <td>0.879233</td>\n",
       "      <td>0.898900</td>\n",
       "      <td>0.602618</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.883116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_multi_nb_tfidf</th>\n",
       "      <td>0.975062</td>\n",
       "      <td>0.974202</td>\n",
       "      <td>0.827289</td>\n",
       "      <td>0.905964</td>\n",
       "      <td>0.787511</td>\n",
       "      <td>2.592868e-01</td>\n",
       "      <td>0.907445</td>\n",
       "      <td>0.924123</td>\n",
       "      <td>0.577492</td>\n",
       "      <td>0.797846</td>\n",
       "      <td>0.541086</td>\n",
       "      <td>0.418215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_multi_nb_tfidf</th>\n",
       "      <td>0.982571</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.904250</td>\n",
       "      <td>0.768044</td>\n",
       "      <td>2.502152e-01</td>\n",
       "      <td>0.887011</td>\n",
       "      <td>0.905157</td>\n",
       "      <td>0.521972</td>\n",
       "      <td>0.770780</td>\n",
       "      <td>0.483489</td>\n",
       "      <td>0.461860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_multi_nb_tfidf</th>\n",
       "      <td>0.971897</td>\n",
       "      <td>0.971358</td>\n",
       "      <td>0.766889</td>\n",
       "      <td>0.877232</td>\n",
       "      <td>0.704708</td>\n",
       "      <td>2.921647e-01</td>\n",
       "      <td>0.885521</td>\n",
       "      <td>0.902983</td>\n",
       "      <td>0.509576</td>\n",
       "      <td>0.765919</td>\n",
       "      <td>0.475411</td>\n",
       "      <td>0.465258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_logReg_OVR</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999223</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>2.968781e-02</td>\n",
       "      <td>0.866202</td>\n",
       "      <td>0.888274</td>\n",
       "      <td>0.604816</td>\n",
       "      <td>0.809760</td>\n",
       "      <td>0.593143</td>\n",
       "      <td>0.691427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_logReg_OVR</th>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>0.993470</td>\n",
       "      <td>0.996306</td>\n",
       "      <td>0.990920</td>\n",
       "      <td>5.431313e-02</td>\n",
       "      <td>0.841773</td>\n",
       "      <td>0.864091</td>\n",
       "      <td>0.578787</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.567609</td>\n",
       "      <td>0.773831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_logReg_OVR</th>\n",
       "      <td>0.999533</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.989750</td>\n",
       "      <td>0.972895</td>\n",
       "      <td>1.084521e-01</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.884867</td>\n",
       "      <td>0.577149</td>\n",
       "      <td>0.798613</td>\n",
       "      <td>0.557472</td>\n",
       "      <td>0.531892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.154375e-08</td>\n",
       "      <td>0.885570</td>\n",
       "      <td>0.897838</td>\n",
       "      <td>0.600801</td>\n",
       "      <td>0.807817</td>\n",
       "      <td>0.582407</td>\n",
       "      <td>3.520746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.541925e-07</td>\n",
       "      <td>0.875868</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>0.583867</td>\n",
       "      <td>0.800570</td>\n",
       "      <td>0.557780</td>\n",
       "      <td>3.382384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.262795e-07</td>\n",
       "      <td>0.871097</td>\n",
       "      <td>0.878811</td>\n",
       "      <td>0.581634</td>\n",
       "      <td>0.800032</td>\n",
       "      <td>0.556447</td>\n",
       "      <td>3.700127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.234378e-01</td>\n",
       "      <td>0.832727</td>\n",
       "      <td>0.854143</td>\n",
       "      <td>0.416180</td>\n",
       "      <td>0.724176</td>\n",
       "      <td>0.405863</td>\n",
       "      <td>0.602035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_RandomForest</th>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.998791</td>\n",
       "      <td>0.996377</td>\n",
       "      <td>1.446901e-01</td>\n",
       "      <td>0.779751</td>\n",
       "      <td>0.802221</td>\n",
       "      <td>0.470990</td>\n",
       "      <td>0.741684</td>\n",
       "      <td>0.453563</td>\n",
       "      <td>0.644454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_RandomForest</th>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.997672</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>1.465335e-01</td>\n",
       "      <td>0.766117</td>\n",
       "      <td>0.787175</td>\n",
       "      <td>0.456280</td>\n",
       "      <td>0.732688</td>\n",
       "      <td>0.443634</td>\n",
       "      <td>0.686401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_review_RandomForest_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.180192e-01</td>\n",
       "      <td>0.855303</td>\n",
       "      <td>0.877119</td>\n",
       "      <td>0.428633</td>\n",
       "      <td>0.728405</td>\n",
       "      <td>0.414498</td>\n",
       "      <td>0.560142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_review_RandomForest_tfidf</th>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.998791</td>\n",
       "      <td>0.996377</td>\n",
       "      <td>1.274129e-01</td>\n",
       "      <td>0.797105</td>\n",
       "      <td>0.816319</td>\n",
       "      <td>0.458710</td>\n",
       "      <td>0.740304</td>\n",
       "      <td>0.438331</td>\n",
       "      <td>0.629900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_review_RandomForest_tfidf</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.997672</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>1.285359e-01</td>\n",
       "      <td>0.785567</td>\n",
       "      <td>0.806099</td>\n",
       "      <td>0.447037</td>\n",
       "      <td>0.735197</td>\n",
       "      <td>0.428314</td>\n",
       "      <td>0.661740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ROC AUC Macro Train  ROC AUC Weighted Train  \\\n",
       "alpha_review_multi_nb                       0.953466                0.955306   \n",
       "stem_review_multi_nb                        0.958344                0.958733   \n",
       "lemma_review_multi_nb                       0.958260                0.958508   \n",
       "alpha_review_multi_nb_tfidf                 0.975062                0.974202   \n",
       "stem_review_multi_nb_tfidf                  0.982571                0.981100   \n",
       "lemma_review_multi_nb_tfidf                 0.971897                0.971358   \n",
       "alpha_review_logReg_OVR                     0.999989                0.999989   \n",
       "stem_review_logReg_OVR                      0.999909                0.999905   \n",
       "lemma_review_logReg_OVR                     0.999533                0.999511   \n",
       "alpha_review_logReg_OVR_tfidf               1.000000                1.000000   \n",
       "stem_review_logReg_OVR_tfidf                1.000000                1.000000   \n",
       "lemma_review_logReg_OVR_tfidf               1.000000                1.000000   \n",
       "alpha_review_RandomForest                   1.000000                1.000000   \n",
       "stem_review_RandomForest                    0.999806                0.999895   \n",
       "lemma_review_RandomForest                   0.999767                0.999861   \n",
       "alpha_review_RandomForest_tfidf             1.000000                1.000000   \n",
       "stem_review_RandomForest_tfidf              0.999861                0.999922   \n",
       "lemma_review_RandomForest_tfidf             0.999881                0.999929   \n",
       "\n",
       "                                 F1 Macro Train  F1 Weighted Train  \\\n",
       "alpha_review_multi_nb                  0.770475           0.869519   \n",
       "stem_review_multi_nb                   0.786932           0.880701   \n",
       "lemma_review_multi_nb                  0.785920           0.879890   \n",
       "alpha_review_multi_nb_tfidf            0.827289           0.905964   \n",
       "stem_review_multi_nb_tfidf             0.822775           0.904250   \n",
       "lemma_review_multi_nb_tfidf            0.766889           0.877232   \n",
       "alpha_review_logReg_OVR                0.999223           0.999555   \n",
       "stem_review_logReg_OVR                 0.993470           0.996306   \n",
       "lemma_review_logReg_OVR                0.981749           0.989750   \n",
       "alpha_review_logReg_OVR_tfidf          1.000000           1.000000   \n",
       "stem_review_logReg_OVR_tfidf           1.000000           1.000000   \n",
       "lemma_review_logReg_OVR_tfidf          1.000000           1.000000   \n",
       "alpha_review_RandomForest              1.000000           1.000000   \n",
       "stem_review_RandomForest               0.997922           0.998791   \n",
       "lemma_review_RandomForest              0.997672           0.998664   \n",
       "alpha_review_RandomForest_tfidf        1.000000           1.000000   \n",
       "stem_review_RandomForest_tfidf         0.997922           0.998791   \n",
       "lemma_review_RandomForest_tfidf        0.997672           0.998664   \n",
       "\n",
       "                                 Balanced Accuracy Score Train  \\\n",
       "alpha_review_multi_nb                                 0.822721   \n",
       "stem_review_multi_nb                                  0.825531   \n",
       "lemma_review_multi_nb                                 0.825136   \n",
       "alpha_review_multi_nb_tfidf                           0.787511   \n",
       "stem_review_multi_nb_tfidf                            0.768044   \n",
       "lemma_review_multi_nb_tfidf                           0.704708   \n",
       "alpha_review_logReg_OVR                               0.998816   \n",
       "stem_review_logReg_OVR                                0.990920   \n",
       "lemma_review_logReg_OVR                               0.972895   \n",
       "alpha_review_logReg_OVR_tfidf                         1.000000   \n",
       "stem_review_logReg_OVR_tfidf                          1.000000   \n",
       "lemma_review_logReg_OVR_tfidf                         1.000000   \n",
       "alpha_review_RandomForest                             1.000000   \n",
       "stem_review_RandomForest                              0.996377   \n",
       "lemma_review_RandomForest                             0.996249   \n",
       "alpha_review_RandomForest_tfidf                       1.000000   \n",
       "stem_review_RandomForest_tfidf                        0.996377   \n",
       "lemma_review_RandomForest_tfidf                       0.996249   \n",
       "\n",
       "                                 Log Loss Train  ROC AUC Macro Test  \\\n",
       "alpha_review_multi_nb              9.681893e-01            0.892345   \n",
       "stem_review_multi_nb               5.083924e-01            0.881971   \n",
       "lemma_review_multi_nb              5.068162e-01            0.879233   \n",
       "alpha_review_multi_nb_tfidf        2.592868e-01            0.907445   \n",
       "stem_review_multi_nb_tfidf         2.502152e-01            0.887011   \n",
       "lemma_review_multi_nb_tfidf        2.921647e-01            0.885521   \n",
       "alpha_review_logReg_OVR            2.968781e-02            0.866202   \n",
       "stem_review_logReg_OVR             5.431313e-02            0.841773   \n",
       "lemma_review_logReg_OVR            1.084521e-01            0.863210   \n",
       "alpha_review_logReg_OVR_tfidf      5.154375e-08            0.885570   \n",
       "stem_review_logReg_OVR_tfidf       1.541925e-07            0.875868   \n",
       "lemma_review_logReg_OVR_tfidf      1.262795e-07            0.871097   \n",
       "alpha_review_RandomForest          1.234378e-01            0.832727   \n",
       "stem_review_RandomForest           1.446901e-01            0.779751   \n",
       "lemma_review_RandomForest          1.465335e-01            0.766117   \n",
       "alpha_review_RandomForest_tfidf    1.180192e-01            0.855303   \n",
       "stem_review_RandomForest_tfidf     1.274129e-01            0.797105   \n",
       "lemma_review_RandomForest_tfidf    1.285359e-01            0.785567   \n",
       "\n",
       "                                 ROC AUC Weighted Test  F1 Macro Test  \\\n",
       "alpha_review_multi_nb                         0.911727       0.646348   \n",
       "stem_review_multi_nb                          0.900650       0.617374   \n",
       "lemma_review_multi_nb                         0.898900       0.602618   \n",
       "alpha_review_multi_nb_tfidf                   0.924123       0.577492   \n",
       "stem_review_multi_nb_tfidf                    0.905157       0.521972   \n",
       "lemma_review_multi_nb_tfidf                   0.902983       0.509576   \n",
       "alpha_review_logReg_OVR                       0.888274       0.604816   \n",
       "stem_review_logReg_OVR                        0.864091       0.578787   \n",
       "lemma_review_logReg_OVR                       0.884867       0.577149   \n",
       "alpha_review_logReg_OVR_tfidf                 0.897838       0.600801   \n",
       "stem_review_logReg_OVR_tfidf                  0.888421       0.583867   \n",
       "lemma_review_logReg_OVR_tfidf                 0.878811       0.581634   \n",
       "alpha_review_RandomForest                     0.854143       0.416180   \n",
       "stem_review_RandomForest                      0.802221       0.470990   \n",
       "lemma_review_RandomForest                     0.787175       0.456280   \n",
       "alpha_review_RandomForest_tfidf               0.877119       0.428633   \n",
       "stem_review_RandomForest_tfidf                0.816319       0.458710   \n",
       "lemma_review_RandomForest_tfidf               0.806099       0.447037   \n",
       "\n",
       "                                 F1 Weighted Test  \\\n",
       "alpha_review_multi_nb                    0.816198   \n",
       "stem_review_multi_nb                     0.806316   \n",
       "lemma_review_multi_nb                    0.800454   \n",
       "alpha_review_multi_nb_tfidf              0.797846   \n",
       "stem_review_multi_nb_tfidf               0.770780   \n",
       "lemma_review_multi_nb_tfidf              0.765919   \n",
       "alpha_review_logReg_OVR                  0.809760   \n",
       "stem_review_logReg_OVR                   0.794466   \n",
       "lemma_review_logReg_OVR                  0.798613   \n",
       "alpha_review_logReg_OVR_tfidf            0.807817   \n",
       "stem_review_logReg_OVR_tfidf             0.800570   \n",
       "lemma_review_logReg_OVR_tfidf            0.800032   \n",
       "alpha_review_RandomForest                0.724176   \n",
       "stem_review_RandomForest                 0.741684   \n",
       "lemma_review_RandomForest                0.732688   \n",
       "alpha_review_RandomForest_tfidf          0.728405   \n",
       "stem_review_RandomForest_tfidf           0.740304   \n",
       "lemma_review_RandomForest_tfidf          0.735197   \n",
       "\n",
       "                                 Balanced Accuracy Score Test  Log Loss Test  \n",
       "alpha_review_multi_nb                                0.681379       1.440893  \n",
       "stem_review_multi_nb                                 0.630341       0.870485  \n",
       "lemma_review_multi_nb                                0.613504       0.883116  \n",
       "alpha_review_multi_nb_tfidf                          0.541086       0.418215  \n",
       "stem_review_multi_nb_tfidf                           0.483489       0.461860  \n",
       "lemma_review_multi_nb_tfidf                          0.475411       0.465258  \n",
       "alpha_review_logReg_OVR                              0.593143       0.691427  \n",
       "stem_review_logReg_OVR                               0.567609       0.773831  \n",
       "lemma_review_logReg_OVR                              0.557472       0.531892  \n",
       "alpha_review_logReg_OVR_tfidf                        0.582407       3.520746  \n",
       "stem_review_logReg_OVR_tfidf                         0.557780       3.382384  \n",
       "lemma_review_logReg_OVR_tfidf                        0.556447       3.700127  \n",
       "alpha_review_RandomForest                            0.405863       0.602035  \n",
       "stem_review_RandomForest                             0.453563       0.644454  \n",
       "lemma_review_RandomForest                            0.443634       0.686401  \n",
       "alpha_review_RandomForest_tfidf                      0.414498       0.560142  \n",
       "stem_review_RandomForest_tfidf                       0.438331       0.629900  \n",
       "lemma_review_RandomForest_tfidf                      0.428314       0.661740  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = [i for i in error.index if 'review' in i]\n",
    "review_error = error.loc[review]\n",
    "review_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Macro Train</th>\n",
       "      <th>ROC AUC Weighted Train</th>\n",
       "      <th>F1 Macro Train</th>\n",
       "      <th>F1 Weighted Train</th>\n",
       "      <th>Balanced Accuracy Score Train</th>\n",
       "      <th>Log Loss Train</th>\n",
       "      <th>ROC AUC Macro Test</th>\n",
       "      <th>ROC AUC Weighted Test</th>\n",
       "      <th>F1 Macro Test</th>\n",
       "      <th>F1 Weighted Test</th>\n",
       "      <th>Balanced Accuracy Score Test</th>\n",
       "      <th>Log Loss Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_combination_multi_nb</th>\n",
       "      <td>0.967296</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.807223</td>\n",
       "      <td>0.888954</td>\n",
       "      <td>0.861842</td>\n",
       "      <td>9.961314e-01</td>\n",
       "      <td>0.908515</td>\n",
       "      <td>0.927266</td>\n",
       "      <td>0.663162</td>\n",
       "      <td>0.828330</td>\n",
       "      <td>0.695499</td>\n",
       "      <td>1.530753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_multi_nb</th>\n",
       "      <td>0.963506</td>\n",
       "      <td>0.964980</td>\n",
       "      <td>0.796566</td>\n",
       "      <td>0.885615</td>\n",
       "      <td>0.840689</td>\n",
       "      <td>5.546042e-01</td>\n",
       "      <td>0.898705</td>\n",
       "      <td>0.918027</td>\n",
       "      <td>0.643388</td>\n",
       "      <td>0.819352</td>\n",
       "      <td>0.661339</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_multi_nb</th>\n",
       "      <td>0.963435</td>\n",
       "      <td>0.964794</td>\n",
       "      <td>0.798084</td>\n",
       "      <td>0.886530</td>\n",
       "      <td>0.842361</td>\n",
       "      <td>5.510565e-01</td>\n",
       "      <td>0.897360</td>\n",
       "      <td>0.917312</td>\n",
       "      <td>0.630741</td>\n",
       "      <td>0.815192</td>\n",
       "      <td>0.648823</td>\n",
       "      <td>0.918122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_multi_nb_tfidf</th>\n",
       "      <td>0.982879</td>\n",
       "      <td>0.981614</td>\n",
       "      <td>0.868290</td>\n",
       "      <td>0.927249</td>\n",
       "      <td>0.847072</td>\n",
       "      <td>2.198836e-01</td>\n",
       "      <td>0.919782</td>\n",
       "      <td>0.936119</td>\n",
       "      <td>0.610337</td>\n",
       "      <td>0.815726</td>\n",
       "      <td>0.576222</td>\n",
       "      <td>0.389288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_multi_nb_tfidf</th>\n",
       "      <td>0.988981</td>\n",
       "      <td>0.987788</td>\n",
       "      <td>0.880290</td>\n",
       "      <td>0.933838</td>\n",
       "      <td>0.844041</td>\n",
       "      <td>2.055390e-01</td>\n",
       "      <td>0.903062</td>\n",
       "      <td>0.920809</td>\n",
       "      <td>0.563693</td>\n",
       "      <td>0.792669</td>\n",
       "      <td>0.523839</td>\n",
       "      <td>0.429720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_multi_nb_tfidf</th>\n",
       "      <td>0.974858</td>\n",
       "      <td>0.975142</td>\n",
       "      <td>0.789251</td>\n",
       "      <td>0.888772</td>\n",
       "      <td>0.735995</td>\n",
       "      <td>2.709453e-01</td>\n",
       "      <td>0.903034</td>\n",
       "      <td>0.921096</td>\n",
       "      <td>0.552174</td>\n",
       "      <td>0.786357</td>\n",
       "      <td>0.513149</td>\n",
       "      <td>0.430855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_logReg_OVR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>1.646652e-02</td>\n",
       "      <td>0.890897</td>\n",
       "      <td>0.911522</td>\n",
       "      <td>0.633926</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>0.619404</td>\n",
       "      <td>0.586487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_logReg_OVR</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.998301</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>0.997367</td>\n",
       "      <td>4.452684e-02</td>\n",
       "      <td>0.881660</td>\n",
       "      <td>0.902915</td>\n",
       "      <td>0.602271</td>\n",
       "      <td>0.811410</td>\n",
       "      <td>0.584451</td>\n",
       "      <td>0.553708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_logReg_OVR</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>2.593149e-02</td>\n",
       "      <td>0.869684</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.598142</td>\n",
       "      <td>0.810461</td>\n",
       "      <td>0.581910</td>\n",
       "      <td>0.680412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.823713e-08</td>\n",
       "      <td>0.900583</td>\n",
       "      <td>0.910300</td>\n",
       "      <td>0.640711</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.622211</td>\n",
       "      <td>3.223883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.416823e-07</td>\n",
       "      <td>0.875123</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.609035</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.595278</td>\n",
       "      <td>3.838801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_logReg_OVR_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.096993e-08</td>\n",
       "      <td>0.874652</td>\n",
       "      <td>0.887361</td>\n",
       "      <td>0.600958</td>\n",
       "      <td>0.809744</td>\n",
       "      <td>0.586300</td>\n",
       "      <td>3.820418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.183898e-01</td>\n",
       "      <td>0.851205</td>\n",
       "      <td>0.872286</td>\n",
       "      <td>0.459656</td>\n",
       "      <td>0.740987</td>\n",
       "      <td>0.436730</td>\n",
       "      <td>0.579194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_RandomForest</th>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>1.394258e-01</td>\n",
       "      <td>0.798914</td>\n",
       "      <td>0.821530</td>\n",
       "      <td>0.502062</td>\n",
       "      <td>0.755432</td>\n",
       "      <td>0.486298</td>\n",
       "      <td>0.626445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_RandomForest</th>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>1.413841e-01</td>\n",
       "      <td>0.795659</td>\n",
       "      <td>0.815066</td>\n",
       "      <td>0.492848</td>\n",
       "      <td>0.752146</td>\n",
       "      <td>0.476423</td>\n",
       "      <td>0.600333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_combination_RandomForest_tfidf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.147608e-01</td>\n",
       "      <td>0.874043</td>\n",
       "      <td>0.895497</td>\n",
       "      <td>0.459406</td>\n",
       "      <td>0.742532</td>\n",
       "      <td>0.437903</td>\n",
       "      <td>0.503530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_combination_RandomForest_tfidf</th>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>1.227593e-01</td>\n",
       "      <td>0.817692</td>\n",
       "      <td>0.838524</td>\n",
       "      <td>0.499606</td>\n",
       "      <td>0.757760</td>\n",
       "      <td>0.474962</td>\n",
       "      <td>0.588319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma_combination_RandomForest_tfidf</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>1.244664e-01</td>\n",
       "      <td>0.817580</td>\n",
       "      <td>0.836734</td>\n",
       "      <td>0.491361</td>\n",
       "      <td>0.756146</td>\n",
       "      <td>0.467140</td>\n",
       "      <td>0.572485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ROC AUC Macro Train  \\\n",
       "alpha_combination_multi_nb                       0.967296   \n",
       "stem_combination_multi_nb                        0.963506   \n",
       "lemma_combination_multi_nb                       0.963435   \n",
       "alpha_combination_multi_nb_tfidf                 0.982879   \n",
       "stem_combination_multi_nb_tfidf                  0.988981   \n",
       "lemma_combination_multi_nb_tfidf                 0.974858   \n",
       "alpha_combination_logReg_OVR                     1.000000   \n",
       "stem_combination_logReg_OVR                      0.999991   \n",
       "lemma_combination_logReg_OVR                     0.999999   \n",
       "alpha_combination_logReg_OVR_tfidf               1.000000   \n",
       "stem_combination_logReg_OVR_tfidf                1.000000   \n",
       "lemma_combination_logReg_OVR_tfidf               1.000000   \n",
       "alpha_combination_RandomForest                   1.000000   \n",
       "stem_combination_RandomForest                    0.999937   \n",
       "lemma_combination_RandomForest                   0.999949   \n",
       "alpha_combination_RandomForest_tfidf             1.000000   \n",
       "stem_combination_RandomForest_tfidf              0.999959   \n",
       "lemma_combination_RandomForest_tfidf             0.999967   \n",
       "\n",
       "                                      ROC AUC Weighted Train  F1 Macro Train  \\\n",
       "alpha_combination_multi_nb                          0.968000        0.807223   \n",
       "stem_combination_multi_nb                           0.964980        0.796566   \n",
       "lemma_combination_multi_nb                          0.964794        0.798084   \n",
       "alpha_combination_multi_nb_tfidf                    0.981614        0.868290   \n",
       "stem_combination_multi_nb_tfidf                     0.987788        0.880290   \n",
       "lemma_combination_multi_nb_tfidf                    0.975142        0.789251   \n",
       "alpha_combination_logReg_OVR                        1.000000        0.999803   \n",
       "stem_combination_logReg_OVR                         0.999991        0.998301   \n",
       "lemma_combination_logReg_OVR                        1.000000        0.999311   \n",
       "alpha_combination_logReg_OVR_tfidf                  1.000000        1.000000   \n",
       "stem_combination_logReg_OVR_tfidf                   1.000000        1.000000   \n",
       "lemma_combination_logReg_OVR_tfidf                  1.000000        1.000000   \n",
       "alpha_combination_RandomForest                      1.000000        1.000000   \n",
       "stem_combination_RandomForest                       0.999975        0.998780   \n",
       "lemma_combination_RandomForest                      0.999980        0.998780   \n",
       "alpha_combination_RandomForest_tfidf                1.000000        1.000000   \n",
       "stem_combination_RandomForest_tfidf                 0.999983        0.998780   \n",
       "lemma_combination_RandomForest_tfidf                0.999987        0.998780   \n",
       "\n",
       "                                      F1 Weighted Train  \\\n",
       "alpha_combination_multi_nb                     0.888954   \n",
       "stem_combination_multi_nb                      0.885615   \n",
       "lemma_combination_multi_nb                     0.886530   \n",
       "alpha_combination_multi_nb_tfidf               0.927249   \n",
       "stem_combination_multi_nb_tfidf                0.933838   \n",
       "lemma_combination_multi_nb_tfidf               0.888772   \n",
       "alpha_combination_logReg_OVR                   0.999873   \n",
       "stem_combination_logReg_OVR                    0.998982   \n",
       "lemma_combination_logReg_OVR                   0.999555   \n",
       "alpha_combination_logReg_OVR_tfidf             1.000000   \n",
       "stem_combination_logReg_OVR_tfidf              1.000000   \n",
       "lemma_combination_logReg_OVR_tfidf             1.000000   \n",
       "alpha_combination_RandomForest                 1.000000   \n",
       "stem_combination_RandomForest                  0.999300   \n",
       "lemma_combination_RandomForest                 0.999300   \n",
       "alpha_combination_RandomForest_tfidf           1.000000   \n",
       "stem_combination_RandomForest_tfidf            0.999300   \n",
       "lemma_combination_RandomForest_tfidf           0.999300   \n",
       "\n",
       "                                      Balanced Accuracy Score Train  \\\n",
       "alpha_combination_multi_nb                                 0.861842   \n",
       "stem_combination_multi_nb                                  0.840689   \n",
       "lemma_combination_multi_nb                                 0.842361   \n",
       "alpha_combination_multi_nb_tfidf                           0.847072   \n",
       "stem_combination_multi_nb_tfidf                            0.844041   \n",
       "lemma_combination_multi_nb_tfidf                           0.735995   \n",
       "alpha_combination_logReg_OVR                               0.999662   \n",
       "stem_combination_logReg_OVR                                0.997367   \n",
       "lemma_combination_logReg_OVR                               0.998816   \n",
       "alpha_combination_logReg_OVR_tfidf                         1.000000   \n",
       "stem_combination_logReg_OVR_tfidf                          1.000000   \n",
       "lemma_combination_logReg_OVR_tfidf                         1.000000   \n",
       "alpha_combination_RandomForest                             1.000000   \n",
       "stem_combination_RandomForest                              0.997867   \n",
       "lemma_combination_RandomForest                             0.997867   \n",
       "alpha_combination_RandomForest_tfidf                       1.000000   \n",
       "stem_combination_RandomForest_tfidf                        0.997867   \n",
       "lemma_combination_RandomForest_tfidf                       0.997867   \n",
       "\n",
       "                                      Log Loss Train  ROC AUC Macro Test  \\\n",
       "alpha_combination_multi_nb              9.961314e-01            0.908515   \n",
       "stem_combination_multi_nb               5.546042e-01            0.898705   \n",
       "lemma_combination_multi_nb              5.510565e-01            0.897360   \n",
       "alpha_combination_multi_nb_tfidf        2.198836e-01            0.919782   \n",
       "stem_combination_multi_nb_tfidf         2.055390e-01            0.903062   \n",
       "lemma_combination_multi_nb_tfidf        2.709453e-01            0.903034   \n",
       "alpha_combination_logReg_OVR            1.646652e-02            0.890897   \n",
       "stem_combination_logReg_OVR             4.452684e-02            0.881660   \n",
       "lemma_combination_logReg_OVR            2.593149e-02            0.869684   \n",
       "alpha_combination_logReg_OVR_tfidf      3.823713e-08            0.900583   \n",
       "stem_combination_logReg_OVR_tfidf       1.416823e-07            0.875123   \n",
       "lemma_combination_logReg_OVR_tfidf      8.096993e-08            0.874652   \n",
       "alpha_combination_RandomForest          1.183898e-01            0.851205   \n",
       "stem_combination_RandomForest           1.394258e-01            0.798914   \n",
       "lemma_combination_RandomForest          1.413841e-01            0.795659   \n",
       "alpha_combination_RandomForest_tfidf    1.147608e-01            0.874043   \n",
       "stem_combination_RandomForest_tfidf     1.227593e-01            0.817692   \n",
       "lemma_combination_RandomForest_tfidf    1.244664e-01            0.817580   \n",
       "\n",
       "                                      ROC AUC Weighted Test  F1 Macro Test  \\\n",
       "alpha_combination_multi_nb                         0.927266       0.663162   \n",
       "stem_combination_multi_nb                          0.918027       0.643388   \n",
       "lemma_combination_multi_nb                         0.917312       0.630741   \n",
       "alpha_combination_multi_nb_tfidf                   0.936119       0.610337   \n",
       "stem_combination_multi_nb_tfidf                    0.920809       0.563693   \n",
       "lemma_combination_multi_nb_tfidf                   0.921096       0.552174   \n",
       "alpha_combination_logReg_OVR                       0.911522       0.633926   \n",
       "stem_combination_logReg_OVR                        0.902915       0.602271   \n",
       "lemma_combination_logReg_OVR                       0.893727       0.598142   \n",
       "alpha_combination_logReg_OVR_tfidf                 0.910300       0.640711   \n",
       "stem_combination_logReg_OVR_tfidf                  0.887885       0.609035   \n",
       "lemma_combination_logReg_OVR_tfidf                 0.887361       0.600958   \n",
       "alpha_combination_RandomForest                     0.872286       0.459656   \n",
       "stem_combination_RandomForest                      0.821530       0.502062   \n",
       "lemma_combination_RandomForest                     0.815066       0.492848   \n",
       "alpha_combination_RandomForest_tfidf               0.895497       0.459406   \n",
       "stem_combination_RandomForest_tfidf                0.838524       0.499606   \n",
       "lemma_combination_RandomForest_tfidf               0.836734       0.491361   \n",
       "\n",
       "                                      F1 Weighted Test  \\\n",
       "alpha_combination_multi_nb                    0.828330   \n",
       "stem_combination_multi_nb                     0.819352   \n",
       "lemma_combination_multi_nb                    0.815192   \n",
       "alpha_combination_multi_nb_tfidf              0.815726   \n",
       "stem_combination_multi_nb_tfidf               0.792669   \n",
       "lemma_combination_multi_nb_tfidf              0.786357   \n",
       "alpha_combination_logReg_OVR                  0.826748   \n",
       "stem_combination_logReg_OVR                   0.811410   \n",
       "lemma_combination_logReg_OVR                  0.810461   \n",
       "alpha_combination_logReg_OVR_tfidf            0.828111   \n",
       "stem_combination_logReg_OVR_tfidf             0.812543   \n",
       "lemma_combination_logReg_OVR_tfidf            0.809744   \n",
       "alpha_combination_RandomForest                0.740987   \n",
       "stem_combination_RandomForest                 0.755432   \n",
       "lemma_combination_RandomForest                0.752146   \n",
       "alpha_combination_RandomForest_tfidf          0.742532   \n",
       "stem_combination_RandomForest_tfidf           0.757760   \n",
       "lemma_combination_RandomForest_tfidf          0.756146   \n",
       "\n",
       "                                      Balanced Accuracy Score Test  \\\n",
       "alpha_combination_multi_nb                                0.695499   \n",
       "stem_combination_multi_nb                                 0.661339   \n",
       "lemma_combination_multi_nb                                0.648823   \n",
       "alpha_combination_multi_nb_tfidf                          0.576222   \n",
       "stem_combination_multi_nb_tfidf                           0.523839   \n",
       "lemma_combination_multi_nb_tfidf                          0.513149   \n",
       "alpha_combination_logReg_OVR                              0.619404   \n",
       "stem_combination_logReg_OVR                               0.584451   \n",
       "lemma_combination_logReg_OVR                              0.581910   \n",
       "alpha_combination_logReg_OVR_tfidf                        0.622211   \n",
       "stem_combination_logReg_OVR_tfidf                         0.595278   \n",
       "lemma_combination_logReg_OVR_tfidf                        0.586300   \n",
       "alpha_combination_RandomForest                            0.436730   \n",
       "stem_combination_RandomForest                             0.486298   \n",
       "lemma_combination_RandomForest                            0.476423   \n",
       "alpha_combination_RandomForest_tfidf                      0.437903   \n",
       "stem_combination_RandomForest_tfidf                       0.474962   \n",
       "lemma_combination_RandomForest_tfidf                      0.467140   \n",
       "\n",
       "                                      Log Loss Test  \n",
       "alpha_combination_multi_nb                 1.530753  \n",
       "stem_combination_multi_nb                  0.918296  \n",
       "lemma_combination_multi_nb                 0.918122  \n",
       "alpha_combination_multi_nb_tfidf           0.389288  \n",
       "stem_combination_multi_nb_tfidf            0.429720  \n",
       "lemma_combination_multi_nb_tfidf           0.430855  \n",
       "alpha_combination_logReg_OVR               0.586487  \n",
       "stem_combination_logReg_OVR                0.553708  \n",
       "lemma_combination_logReg_OVR               0.680412  \n",
       "alpha_combination_logReg_OVR_tfidf         3.223883  \n",
       "stem_combination_logReg_OVR_tfidf          3.838801  \n",
       "lemma_combination_logReg_OVR_tfidf         3.820418  \n",
       "alpha_combination_RandomForest             0.579194  \n",
       "stem_combination_RandomForest              0.626445  \n",
       "lemma_combination_RandomForest             0.600333  \n",
       "alpha_combination_RandomForest_tfidf       0.503530  \n",
       "stem_combination_RandomForest_tfidf        0.588319  \n",
       "lemma_combination_RandomForest_tfidf       0.572485  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combination = [i for i in error.index if 'combination' in i]\n",
    "comb_error = error.loc[combination]\n",
    "comb_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the model more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sentiment.drop('Sentiment', axis=1)\n",
    "y = df_sentiment['Sentiment']\n",
    "\n",
    "alpha_title_train, alpha_title_test, alpha_title_y_train, alpha_title_y_test = train_test_split(X['alpha_title'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "alpha_review_train, alpha_review_test, alpha_review_y_train, alpha_review_y_test = train_test_split(X['alpha_review'], y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "alpha_combination_train, alpha_combination_test, alpha_combination_y_train, alpha_combination_y_test = train_test_split(X['alpha_combination'], y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title = Pipeline([('vect', CountVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
    "                        ('clf', MultinomialNB(alpha=0.1))])\n",
    "\n",
    "model_review = Pipeline([('vect', CountVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
    "                     ('clf', MultinomialNB(alpha=1))])\n",
    "\n",
    "model_combination = Pipeline([('vect', CountVectorizer(max_features=15000, ngram_range=(1, 2))),\n",
    "                        ('clf', MultinomialNB(alpha=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title Model\n",
      "Cross Validation Balanced Accuracy (Train Data):  [0.60790807 0.60549188 0.6194705  0.60729322 0.60128874]\n",
      "Balanced Accuracy of Cross Val : 0.61 (+/- 0.01)\n",
      "Balanced Accuracy Score (Test Data):  0.6125669646419161\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAHRCAYAAACrT/nKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3QV9bnG8WcnGyRXA2L1oFxELhYUMCdi2xPwgjGopQhGN1BDC6hIFQgihQQBbbi1KBQTLoq23oqkKGgKRZQgpkQEG41KrFYFEQEVCBCygewkM+cPTncP5wARTTLzy3w/a2UtJxlmv1my2tfnfWfGZ9u2LQAAAJeKcLoAAACA06FZAQAArkazAgAAXI1mBQAAuBrNCgAAcDWaFQAA4Gr++rz4eWdfUp+XhwcdrAw6XQIaEcuynC4BjVBVaFfDft6+bXV+zSYt29f5Nb8PkhUAAOBq9ZqsAACAembVOF1BvSNZAQAArkayAgCAyezGv3tFsgIAAFyNZAUAAJN54K42mhUAAAxmMwYCAABwFskKAAAm88AYiGQFAAC4GskKAAAm88DOCs0KAAAm4wm2AAAAziJZAQDAZB4YA5GsAAAAVyNZAQDAZB64dZlmBQAAg/EEWwAAAIeRrAAAYDIPjIFIVgAAgKuRrAAAYDJ2VgAAAJxFsgIAgMk88Lh9mhUAAEzGGAgAAMBZJCsAAJiMW5cBAACcRbICAIDJPLCzQrMCAIDJGAMBAAA4i2QFAACD2Xbjf84KyQoAAHA1khUAAEzGgi0AAHA1DyzY0qwAAIAzUlVVpaysLO3atUuhUEijRo3S+eefr7vvvlvt2rWTJA0ePFg33nijcnNztWHDBvn9fmVlZalbt27asWOHJk2aJJ/Pp44dO2ratGmKiDj1ZgrNCgAAJnNgDJSfn6+EhATNmTNHBw4c0IABA3TPPfdo2LBhGj58ePi80tJSbdmyRcuXL9eePXs0evRovfjii5o1a5YyMjJ05ZVXaurUqSooKFBKSsopP49mBQAAnJG+ffsqNTU1fBwZGamtW7dq+/btKigoUNu2bZWVlaXi4mIlJyfL5/OpVatWqqmpUVlZmUpLS9WzZ09JUu/evVVUVESzAgBAo2XV/a3LeXl5ysvLCx8HAgEFAoHwcUxMjCSpoqJCY8aMUUZGhkKhkG699VZdeumlWrRokRYsWKC4uDglJCSc8OcOHz4s27bl8/lO+N7p0KwAAGCyehgD/d/m5GT27Nmje+65R0OGDFG/fv1UXl6u+Ph4SVJKSoqys7PVp08fBYPB8J8JBoOKi4s7YT8lGAyG/9yp8JwVAABwRvbt26fhw4drwoQJSktLkySNGDFC77//viRp06ZN6tq1qxITE7Vx40ZZlqXdu3fLsiy1aNFCXbp00ebNmyVJhYWFSkpKOu3n+Wzbtuvrlznv7Evq69LwqIOVwdpPAr4lywO3fKLhVYV2NejnHXsrr/aTzlCzH50+VZk+fbrWrFmj9u3bh7+XkZGhOXPmqEmTJmrZsqWys7MVGxurnJwcFRYWyrIsZWZmKikpSdu3b9eUKVNUVVWl9u3ba/r06YqMjDzl59GswCg0K6hLNCuoD15oVhoaOysAAJjMA0+wZWcFAAC4GskKAAAm88A4k2YFAACTeaBZYQwEAABcjWQFAACD2XbdP8HWbUhWAACAq5GsAABgMg/srNCsAABgMp6zAgAA4CySFQAATOaBMRDJCgAAcDWSFQAATOaBnRWaFQAATMYYCAAAwFkkKwAAmMwDYyCSFQAA4GokKwAAmIydFQAAAGeRrAAAYDIPJCs0KwAAmIwFWwAAAGeRrAAAYDIPjIFIVgAAgKuRrAAAYDIP7KzQrDQAv9+v3y+YodZtLtBZZzXVvDmLtHbN65Kk38ycpE8/3a5n/pAnSRo1ergGpN0ky7I0/5HHtGbVOidLh8tdcUUPzZiRpeuvv00Xt2+nJU88ItuWPiz9WGPGTpZt23rxhT+oxTkJqqqq1rGjx/Sz/kOdLhsu5/f79Yc//F7t2rZWTU2N7h41QVOmjNf5550rSWrbtrU2b3lHt9/+K4crhSRPjIFoVhpAWuBnOlB2UPeOnKjmzRO07m8r9PctJcp57Le6uEM7ffrok5Kk+LPjdMfI2/Wjy1MVHROlgr+tpFnBKY2/724NGXKLgsEjkqTf/W6qHnxwjgoL31Juzkz165eq/PxXdPHFbdXj8j4OVwuT3HDDtfL7/ep9VX/16dNLv/nNRAUCd0mSEhLO1rrXluv++x90tkh4yrfeWbE80LnVl/yXXtHsGY+Gj2tqahQTG62HZ+Vq+bL88PePBI/qy527FR0TpejoKNm27US5MMRn23YoELgzfHz55ZepsPAtSdLatRvU59pk/eAHLXX22Wdr5Yo/av36F3XjDTQtqN0nn2yT3x8pn8+n+Pg4VVVVh382bep4LVjwB3311TcOVogT2Fbdf7nMaZOVnTt3atasWdq6dav8fr8sy1KnTp2UmZmpiy66qKFqNN6R//kv35jYGD35zHzNzp6vL3bs0hc7dunalN4nnLt711f62+ZVioyM1KNzH3eiXBjipZfWqG3bC8PHPp8v/M+HKyoUf3acmjZtovnzH1dO7pNq0SJBG15fqbf/XqK9e/c7UTIMUVFxRO3attbWrYVqeU5z3XzzLyVJ5557jq65NlnjSVXQwE7brEyePFnjx49X9+7dw98rKSlRZmamli1bVu/FNSatLjhff/xTrp56YqlWvLDqpOf0Seml8847V1d0u06StGzFk9ry1jt6950PGrJUGOp/p59xsbE6dLBcX321V48veVY1NTXau3e/Skq2qlOni2lWcFpjx9ypV1/boAcemK0LL2ylV9f+WZcn9tEtA3+qZcteIml3Gw/8+zjtGCgUCp3QqEhSjx496rWgxujcc89R3sonNX3aw3r+uRWnPO/gwXIdPXZMlZUhVVaGVH6oXPEJ8Q1YKUz23ntb1bv3jyRJqalXa2PRFvW5NllL/7RIkhQTE62uXTvro48+cbJMGODAwUM6dOiwJKms7ICaNPErMjJC1/ZJ1tpX1jtcHf4fy6r7L5c5bbLSuXNnZWZmqlevXoqLi1MwGNQbb7yhzp07N1R9jcLY8SOVkBCvcRN+pXETjm/PD0m7U8eOVZ5w3uZNxSp5Z6vWFOTJsmxtfqtYb6wvcqJkGGjixGwtXPQ7NW3SRB99/KlWrFgty7KUknKVCt94WZZlaerU32n//gNOlwqXmz//cS1ZMlevr1+hpk2baMrU2Tpy5Kg6dbpY27Z/4XR58CCffZotTtu2tW7dOhUXF6uiokKxsbFKTExUSkrKCfPxUznv7EvqtFjgYGXQ6RLQiDDOQH2oCu1q0M87mvdQnV8zKjCtzq/5fZw2WfH5fEpJSVFKSkpD1QMAAHACnrMCAIDJPJAQ8m4gAADgaiQrAACYzAPJCs0KAAAmc+ETZ+saYyAAAOBqJCsAAJjMA2MgkhUAAOBqJCsAAJjs1M92bTRoVgAAMBljIAAAAGeRrAAAYDKSFQAAAGeRrAAAYDIPPBSOZgUAAIPZVuO/G4gxEAAAcDWSFQAATMaCLQAAgLNIVgAAMJkHFmxJVgAAgKuRrAAAYDIP3A1EswIAgMlYsAUAAHAWyQoAACYjWQEAAHAWyQoAACazWbAFAABuxhgIAADAWSQrAACYzAPPWSFZAQAArkayAgCAyTzwbiCaFQAATMYYCAAAwFkkKwAAGMzm1mUAAABnkawAAGAydlYAAACcRbICAIDJuHUZAAC4GmMgAAAAZ5GsAABgMg/cukyzAgAAzkhVVZWysrK0a9cuhUIhjRo1Sh06dNCkSZPk8/nUsWNHTZs2TREREcrNzdWGDRvk9/uVlZWlbt26aceOHSc991QYAwEAYDLLrvuvWuTn5yshIUFLly7VkiVLlJ2drVmzZikjI0NLly6VbdsqKChQaWmptmzZouXLl2vu3Ll66KGHJOmk554OyQoAACZz4G6gvn37KjU1NXwcGRmp0tJS9ezZU5LUu3dvFRUV6aKLLlJycrJ8Pp9atWqlmpoalZWVnfTclJSUU34eyQoAADhBXl6eBg4cGP7Ky8s74ecxMTGKjY1VRUWFxowZo4yMDNm2LZ/PF/754cOHVVFRodjY2BP+3OHDh0967umQrAAAYLJ6uHU5EAgoEAic9pw9e/bonnvu0ZAhQ9SvXz/NmTMn/LNgMKj4+HjFxsYqGAye8P24uLgT9lP+de7pkKwAAIAzsm/fPg0fPlwTJkxQWlqaJKlLly7avHmzJKmwsFBJSUlKTEzUxo0bZVmWdu/eLcuy1KJFi5Oeezo+27br7Wky5519SX1dGh51sDJY+0nAt2R54JZPNLyq0K4G/byKzFvq/Jqxs1487c+nT5+uNWvWqH379uHvTZ48WdOnT1dVVZXat2+v6dOnKzIyUjk5OSosLJRlWcrMzFRSUpK2b9+uKVOm/L9zT4VmBUahWUFdollBfWjwZmXiwDq/ZuxvV9T5Nb8PxkAAAMDVWLAFAMBkvBsIAADAWSQrAACYzIGHwjU0khUAAOBqJCsAAJjMAzsrNCsAABjM9kCzwhgIAAC4GskKAAAmI1kBAABwFskKAAAm88BrI2hWAAAwGWMgAAAAZ5GsAABgMpIVAAAAZ5GsAABgMNtu/MkKzQoAACZjDAQAAOAskhUAAEzmgWSlXpuViqpj9Xl5eFBc0yinS0AjEqqpdroEAN8CyQoAAAbjrcsAAAAOI1kBAMBkHkhWaFYAADBZ43+PIWMgAADgbiQrAAAYjAVbAAAAh5GsAABgMg8kKzQrAACYjAVbAAAAZ5GsAABgMBZsAQAAHEayAgCAyTyws0KzAgCAwRgDAQAAOIxkBQAAk3lgDESyAgAAXI1kBQAAg9keSFZoVgAAMJkHmhXGQAAAwNVIVgAAMJgXxkAkKwAAwNVIVgAAMBnJCgAAgLNIVgAAMJgXdlZoVgAAMJgXmhXGQAAAwNVIVgAAMBjJCgAAgMNIVgAAMJntc7qCekezAgCAwRgDAQAAOIxkBQAAg9lW4x8DkawAAABXI1kBAMBgXthZoVkBAMBgtgfuBmIMBAAAXI1kBQAAg3lhDESyAgAAXI1kBQAAg3HrMgAAgMNIVgAAMJhtO11B/aNZAQDAYIyBAAAAHEayAgCAwUhWAAAAHEayAgCAwViwBQAArsYYCAAAwGEkKwAAGIy3LgMAADiMZAUAAIN54a3LNCsAABjMYgwEAADw/7333ntKT0+XJJWWlqpXr15KT09Xenq6/vrXv0qScnNzlZaWpkGDBun999+XJO3YsUODBw/WkCFDNG3aNFlW7dEQyQoAAAZzYsF2yZIlys/PV1RUlCTpww8/1LBhwzR8+PDwOaWlpdqyZYuWL1+uPXv2aPTo0XrxxRc1a9YsZWRk6Morr9TUqVNVUFCglJSU034eyQoAADgjbdq0UU5OTvh469at2rBhg37+858rKytLFRUVKi4uVnJysnw+n1q1aqWamhqVlZWptLRUPXv2lCT17t1bb775Zq2fR7ICAIDB6uOhcHl5ecrLywsfBwIBBQKB8HFqaqq+/PLL8HG3bt1066236tJLL9WiRYu0YMECxcXFKSEhIXxOTEyMDh8+LNu25fP5TvhebWhWAADACf5vc1KblJQUxcfHh/85Oztbffr0UTAYDJ8TDAYVFxeniIiIE773rz93OoyBAAAwmG3X/deZGjFiRHiBdtOmTeratasSExO1ceNGWZal3bt3y7IstWjRQl26dNHmzZslSYWFhUpKSqr1+iQrAAAYzA3vBnrwwQeVnZ2tJk2aqGXLlsrOzlZsbKySkpIUCARkWZamTp0qSZo4caKmTJmiuXPnqn379kpNTa31+j7brr/3NcZEt6uvS8OjovxNnS4BjUioptrpEtAIlQe3NejnfXjxTXV+zS6fra7za34fJCsAABiMh8IBAAA4jGQFAACDeeGtyzQrAAAYrP42T92DMRAAAHA1khUAAAzGgi0AAIDDaFYaUNIVPbTmlWWSpEsu6aDX1i3XuoIXNO/32eHHD895eJo2Fv1Fa15ZpjWvLFN8fJyTJcPlEpO66eXVz0qSunXvoldff0F/eWWpZs2ZEn73xozfTta6DS/q5dXPKjGpm5PlwgBJSd21es1SSVL3Hl310SdvavWapVq9ZqkG3nL8eR6/nTNFG/72slavWaqkpO5OlgsdX7Ct6y+3YQzUQMaNG6nBgwcoeOSoJOnBh36tB6fNUVHRFj322MO66acp+kv+WvXocan6/2yo9u8/4HDFcLvRY+/QrYP668j//J2aOz9bmb+erre3vKvMKRlKu62fDh0qV4eOFynlmjQ1b56gP694QtddfYvDlcOtxo67S4MGD9CR4BFJUvfuXZWb86RyH30yfE7fvteqY8f2uqb3zWreIkErXnpKV/fq71TJEAu2qEPbtu3Q4MF3h4+HDL5bRUVb1KRJE513/rn65uu98vl86nBxO+XkztK6ghc0dOitDlYMt9u+/Qv98vZ7w8f/ccH5envLu5KkLW+9oyt/9J/q3LmDXi/YKNu2VVZ2QDWWpR/8oKVTJcPltm/7QrcPHhU+7nH5ZUrte43WrF2m3IWzFRsbo84/7KCCdX87/ndq/wFZNTX6wXn8nUL9ollpIC+//Iqqqv79aG/LstS69QX6e/GrOuec5vrkk22KiYnWosVPa8TwDN3c/xe68650XXrpJQ5WDTdblf/qCX+ndny+Uz/5ryskSak3XKPomGh98ME/dO11veT3+9W2XWt1vqSDomOinCoZLpf/8iuqqqoKHxcXv6cpWbN1Q+ogfb79C03KGqMP3v9Q16X0lt/vV7t2rXXJDzsqJjrawaph2b46/3IbmhUH7dy5S927XaMnnviTZs+eoiNHjmrhgj/q6NFjqqgI6o0Nb+qyy37odJkwxJhRmRo7fqSeX/649u0tU9n+Mm1YX6RNRW9r5apnNOreYXq/pFRlZQedLhWGWJW/ViUlWyVJf/nLq+rWvavWF2xU0cYtWvXXP+ne0SNU8u5WlZUxtkb9Om2zkp6erkGDBp3wFQgENGjQoIaqr9H68/IluvjidpKkisNBWbaljh0v0rp1LygiIkJ+v18//skV4f+hAGqTknq1xv4qS4NvvUvNWyRow+tv6uIO7bRvb5n69R2iR+c9LsuyVH7osNOlwhArX35a//mfx5eyr776Jyp59wN16HCR9u7dr77XBzRv7mOyLEuH+DvlKM8v2N5///164IEHtGDBAkVGRjZUTZ7wyMOL9NjjDysUqtLRo0d1z68m6quv9iov7yVteGOlqqqqtXTpCv3jH584XSoMse2zz/X8C0t09OhRbSzcrHWvvqGzzmqqa6/rpZ8PTVPlsUr9evxDTpcJg4zLmKKHH3lQoVCVvvl6r8aMnqxQKKTrUq7S0F/cpmPHKjX+vmlOlwkP8Nn26feIn3jiCbVt21YpKSlnfPGY6HbftS7gpKL8TZ0uAY1IqKa69pOAM1Qe3Nagn7e51cA6v+aVu1fU+TW/j1pvXb7jjjsaog4AAPAdeODOZRZsAQCAu/FQOAAADObGW43rGskKAABwNZIVAAAM5sZbjesazQoAAAaznC6gATAGAgAArkayAgCAwWw1/jEQyQoAAHA1khUAAAxmeeCpcDQrAAAYzGIMBAAA4CySFQAADMaCLQAAgMNIVgAAMBgPhQMAAHAYyQoAAAbzws4KzQoAAAZjDAQAAOAwkhUAAAxGsgIAAOAwkhUAAAzGgi0AAHA1q/H3KoyBAACAu5GsAABgMN66DAAA4DCSFQAADGY7XUADoFkBAMBgPGcFAADAYSQrAAAYzPKxYAsAAOAokhUAAAzmhQVbkhUAAOBqJCsAABjMC3cD0awAAGAw3g0EAADgMJIVAAAMxruBAAAAHEayAgCAwbxw6zLNCgAABmPBFgAAwGEkKwAAGMwLz1khWQEAAK5GsgIAgMFYsAUAAK7Ggi0AAIDDSFYAADAYC7YAAAAOI1kBAMBgJCsAAAAOI1kBAMBgtgfuBqJZAQDAYIyBAAAAHEayAgCAwUhWAAAAHEayAgCAwXg3EAAAcDXeDQQAAOAwkhUAAAzGgi0AAMBJvPfee0pPT5ck7dixQ4MHD9aQIUM0bdo0WdbxFio3N1dpaWkaNGiQ3n///dOeezo0KwAAGMyqh6/aLFmyRA888IAqKyslSbNmzVJGRoaWLl0q27ZVUFCg0tJSbdmyRcuXL9fcuXP10EMPnfLc2tCsAABgMLsevmrTpk0b5eTkhI9LS0vVs2dPSVLv3r315ptvqri4WMnJyfL5fGrVqpVqampUVlZ20nNrw84KAAA4QV5envLy8sLHgUBAgUAgfJyamqovv/wyfGzbtny+47clxcTE6PDhw6qoqFBCQkL4nH99/2Tn1oZmBQAAg9XHrcv/tzmpTUTEvwc1wWBQ8fHxio2NVTAYPOH7cXFxJz231ut/60oAAABOokuXLtq8ebMkqbCwUElJSUpMTNTGjRtlWZZ2794ty7LUokWLk55bG5IVAAAM5oZblydOnKgpU6Zo7ty5at++vVJTUxUZGamkpCQFAgFZlqWpU6ee8tza+Gzbrrcn9cZEt6uvS8OjovxNnS4BjUioptrpEtAIlQe3NejnzW57e51fc9KO5+r8mt8HyQoAAAbj3UDfU2V1VX1eHh4U1zTK6RLQiOzZ9orTJQDfm+WBdoUFWwAA4GqMgQAAMJgbFmzrG8kKAABwNZIVAAAM1vg3VmhWAAAwGmMgAAAAh5GsAABgsPp4N5DbkKwAAABXI1kBAMBgXngoHM0KAAAGa/ytCmMgAADgciQrAAAYjFuXAQAAHEayAgCAwViwBQAArtb4WxXGQAAAwOVIVgAAMBgLtgAAAA4jWQEAwGBeWLAlWQEAAK5GsgIAgMEaf65CswIAgNFYsAUAAHAYyQoAAAazPTAIIlkBAACuRrICAIDBvLCzQrMCAIDBeM4KAACAw0hWAAAwWOPPVUhWAACAy5GsAABgMC/srNCsAABgMC/cDcQYCAAAuBrJCgAABuMJtgAAAA4jWQEAwGDsrAAAADiMZAUAAIN5YWeFZgUAAIMxBgIAAHAYyQoAAAaz7MY/BiJZAQAArkayAgCAwRp/rkKzAgCA0bzwIkPGQAAAwNVIVgAAMJgXnrNCsgIAAFyNZAUAAIN54aFwNCsAABiMBVsAAACHkawAAGAwFmwBAAAcRrICAIDBvLBgS7ICAABcjWQFAACD2R546zLNCgAABuPWZQAAAIeRrAAAYDAWbAEAABxGsgIAgMG88FA4mhUAAAzGgi0AAIDDSFYAADCYF56zQrICAABcjWQFAACDeeHWZZoVAAAM5oW7gRgDAQAAVyNZAQDAYF64dZlmxQETf32v+v30ejVp2kSLFz+td979QAtzZ6u6ulr//GSb7hp5vye2u/Hd+f1+zVswQ61bt9JZZzXVvIcXa9eXezTjt5NlWZYqK0Maffck7du7X6PuHaab026SbVmaP/dxrVm1zuny4RJV1dWaMnOedu/5WqGqKo38xWCtfu117Ss7IEnavedrdet6iR7+TabmP/aU3vp7iXySMseN0mVdOutQ+WHdNOgOdWjfVpLUp/dPlH7bzQ7+RmisaFYa2FW9f6wf/zhJva7qr+joKI2/727ddNN1mj5jnta8sl7PPJ2jm268TqtWv+Z0qXCxtEA/HSg7qNEjJ6p58wS9Vviidn6xS5MnzlDpBx8p/Ze36d6MOzT3dws1YuTt+nFiX0VHR6lg40qaFYStWrteCfFxmj11gg4eKlfasHu1bsUzkqRD5Yc1fPQkTRwzUv/456d6v/QjLX18nnZ/9Y1GT3pIK55eqA8//lQ3XneVsu77lcO/ibd54T9uz7hZCYVCatq0aX3U4gnXX3+Vtm79SC++8KTi4+I0cVK2LMtS8xYJkqS4uFhVVVU5XCXcLv+ltfrLy2vDxzU1NRo5fLy++XqvpOPJS+WxSh0JHtWXO3crOjpK0TFRsiwv3DeAbyv1ml66/urk8LE/MjL8zwuefE5D0n6mc1u20LktW+ixuTPk8/m0+6uvdU7z4/979eHHn+jDf36mX94zQS2aJygzY5TObdmiwX8PNH6nbFbWr1+v7Oxs+f1+jRs3TjfeeKMk6Y477tAzzzzTYAU2Nuec00Jt21yon938C110URutXPFH/Sb7EeXMn6GszLEqP1SuDW9scrpMuNyR4BFJUkxstJ545veaPX1+uFFJ6tlDw+4cogE3pkuSdu/6SoWbVykyMkKPzlviWM1wn+joKElSMHhE4ybP0Og7h0qS9h84qM1/L9HEMXeFz/X7IzX/saf0p+X5yho3SpJ0UdvW6tK5o358xeVatXa9Zs5bqHkzHmj4X8TjnNpZufnmmxUXFydJuvDCCxUIBDRjxgxFRkYqOTlZ9957ryzL0oMPPqiPP/5YTZs21fTp09W2bdsz/qxTNiuLFy/WypUrZdu2xo4dq8rKSg0YMMATcVN9Kis7oI8//kxVVVX65z8/07FjlXr26Vz1SOyjDz/8p0bd/QvN+d1UjRk72elS4XKtLjhff3wuR089+bxWvrBaktR/wA0ae/9I3X7b3dq//4Cuv+EanXf+uerZ/TpJ0rIVT+jtt97Ru+984GTpcJE9X+/V2MxsDRp4k266/hpJ0muvb9SN11+tyP+VtEjS2JG/1B2336Yhd41TYveuujKxu5o1O0uS1Oeqnyj3iWcbvH44c+tyZWWlJOnZZ//977x///7KyclR69atddddd6m0tFS7du1SKBRSXl6eSkpKNHv2bC1atOiMP++Uty43adJECQkJat68uRYuXKjnnntOb731lnw+33f4tfAvRUVvK/X6qyVJ//Ef5ykmOkqffbZD5eUVko4vtDVvfraDFcIELc89R8tWPKHsaY/o+edWSJJuua2fht05RANv+oW+2PGlJOnQwXIdO1qpysqQKitDOnSoXPFnxzlZOlxkX9kB3TVusu771TAN/Glq+Pub3n5XvX50Rfh4c3GJpj+yQJLU9Kym8vv9ioiI0NTZ8/XahqLj5/y9RF0v6diwvwkjbX4AAAZOSURBVAAc89FHH+no0aMaPny4hg4dqrfffluhUEht2rSRz+dTcnKyNm3apOLiYvXq1UuS1KNHD23duvU7fd4pk5ULLrhAs2bN0tixYxUbG6vc3FyNGDFC5eXl3+03gyRp9V/XqVevK7XpzdWKiIjQmLGTFQwe0dLnFqq6ulqhUJVGjprgdJlwubHj71JCQrzu+/Uo3ffrUYqIiNAlXTrqy5279YfnHpUkbSp6W3Nm5ark6g/013XLZFm2trxVrDdef9Ph6uEWS57JU/nhCi1+6nktfup5SdLiR7L1+Rdf6sJW54fPS+pxmdau/5tuv3u8rJoaDb7lp7qw1fkaN2qYpsycp2UrVymqWTP9ZlKGU7+Kp1n1MPHIy8tTXl5e+DgQCCgQCISPmzVrphEjRujWW2/V559/rjvvvFPx8fHhn8fExGjnzp2qqKhQbGxs+PuRkZGqrq6W339mK7M++xRznerqauXn5+uGG25QVNTxuea+ffv02GOPafLkbzei8De94IyKAWrTMjq+9pOAb2nnp6udLgGNUJOW7Rv083pf0KfOr1m4q+C0Pw+FQrIsS82aNZMkDRgwQIcOHdL69eslSU8//bSqq6v1zTffqHv37uG91969e6uwsPCM6znlGMjv92vgwIHhRkWSWrZs+a0bFQAAUP/seviqzQsvvKDZs2dLkr7++msdPXpU0dHR+uKLL2TbtjZu3KikpCQlJiaGm5OSkhJ16tTpO/2OPGcFAACDOXE3UFpamjIzMzV48GD5fD7NnDlTERERuv/++1VTU6Pk5GR1795dl112mYqKijRo0CDZtq2ZM2d+p8875RioLjAGQl1jDIS6xBgI9aGhx0D/dcG1dX7Nol3r6/ya3wfJCgAABvPCu4F46zIAAHA1khUAAAzmhYe10qwAAGAwxkAAAAAOI1kBAMBgTrwbqKGRrAAAAFcjWQEAwGBeWLAlWQEAAK5GsgIAgMG8cDcQzQoAAAZjDAQAAOAwkhUAAAzmhTEQyQoAAHA1khUAAAzmhYfC0awAAGAwiwVbAAAAZ5GsAABgMC+MgUhWAACAq5GsAABgMC/srNCsAABgMMZAAAAADiNZAQDAYF4YA5GsAAAAVyNZAQDAYOysAAAAOIxkBQAAg3lhZ4VmBQAAgzEGAgAAcBjJCgAABrNty+kS6h3JCgAAcDWSFQAADGZ5YGeFZgUAAIPZHrgbiDEQAABwNZIVAAAM5oUxEMkKAABwNZIVAAAM5oWdFZoVAAAM5oXH7TMGAgAArkayAgCAwXg3EAAAgMNIVgAAMJgXFmxJVgAAgKuRrAAAYDAvPBSOZgUAAIMxBgIAAHAYyQoAAAbjoXAAAAAOI1kBAMBgXthZoVkBAMBgXrgbiDEQAABwNZIVAAAM5oUxEMkKAABwNZIVAAAM5oVbl2lWAAAwmM2CLQAAgLNIVgAAMJgXxkAkKwAAwNVIVgAAMBi3LgMAADiMZAUAAIN54W4gmhUAAAzGGAgAAMBhJCsAABiMZAUAAMBhJCsAABis8ecqks/2Qn4EAACMxRgIAAC4Gs0KAABwNZoVAADgajQrAADA1WhWAACAq9GsAAAAV6NZcZBlWZo6daoCgYDS09O1Y8cOp0tCI/Hee+8pPT3d6TLQCFRVVWnChAkaMmSI0tLSVFBQ4HRJ8CAeCuegdevWKRQKKS8vTyUlJZo9e7YWLVrkdFkw3JIlS5Sfn6+oqCinS0EjkJ+fr4SEBM2ZM0cHDhzQgAED1KdPH6fLgseQrDiouLhYvXr1kiT16NFDW7dudbgiNAZt2rRRTk6O02Wgkejbt6/Gjh0bPo6MjHSwGngVzYqDKioqFBsbGz6OjIxUdXW1gxWhMUhNTZXfT2iKuhETE6PY2FhVVFRozJgxysjIcLokeBDNioNiY2MVDAbDx5Zl8X8yAFxnz549Gjp0qPr3769+/fo5XQ48iGbFQYmJiSosLJQklZSUqFOnTg5XBAAn2rdvn4YPH64JEyYoLS3N6XLgUfxnvINSUlJUVFSkQYMGybZtzZw50+mSAOAEixcvVnl5uRYuXKiFCxdKOr7E3axZM4crg5fw1mUAAOBqjIEAAICr0awAAABXo1kBAACuRrMCAABcjWYFAAC4Gs0KAABwNZoVAADgajQrAADA1f4bAnzOjrDviGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.52       410\n",
      "           1       0.37      0.40      0.39       493\n",
      "           2       0.92      0.90      0.91      3031\n",
      "\n",
      "    accuracy                           0.80      3934\n",
      "   macro avg       0.60      0.61      0.61      3934\n",
      "weighted avg       0.81      0.80      0.80      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Title Model')\n",
    "cross_score = cross_val_score(model_title, alpha_title_train, alpha_title_y_train, scoring='balanced_accuracy')\n",
    "model_title.fit(alpha_title_train, alpha_title_y_train)\n",
    "y_pred = model_title.predict(alpha_title_test)\n",
    "score = balanced_accuracy_score(alpha_title_y_test, y_pred)\n",
    "print('Cross Validation Balanced Accuracy (Train Data): ', cross_score)\n",
    "print(\"Balanced Accuracy of Cross Val : %0.2f (+/- %0.2f)\" % (cross_score.mean(), cross_score.std() * 2))\n",
    "print('Balanced Accuracy Score (Test Data): ', score)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_matrix(alpha_title_y_test, y_pred), annot=True, fmt='g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(alpha_title_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Model\n",
      "Cross Validation Balanced Accuracy (Train Data):  [0.65858891 0.64042789 0.65549983 0.66353104 0.65650763]\n",
      "Balanced Accuracy of Cross Val : 0.65 (+/- 0.02)\n",
      "Balanced Accuracy Score (Test Data):  0.6813790004373798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.61      0.57       410\n",
      "           1       0.39      0.57      0.46       493\n",
      "           2       0.95      0.86      0.91      3031\n",
      "\n",
      "    accuracy                           0.80      3934\n",
      "   macro avg       0.63      0.68      0.65      3934\n",
      "weighted avg       0.84      0.80      0.82      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Review Model')\n",
    "cross_score = cross_val_score(model_review, alpha_review_train, alpha_review_y_train, scoring='balanced_accuracy')\n",
    "model_review.fit(alpha_review_train, alpha_review_y_train)\n",
    "y_pred = model_review.predict(alpha_review_test)\n",
    "score = balanced_accuracy_score(alpha_review_y_test, y_pred)\n",
    "print('Cross Validation Balanced Accuracy (Train Data): ', cross_score)\n",
    "print(\"Balanced Accuracy of Cross Val : %0.2f (+/- %0.2f)\" % (cross_score.mean(), cross_score.std() * 2))\n",
    "print('Balanced Accuracy Score (Test Data): ', score)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_matrix(alpha_review_y_test, y_pred), annot=True, fmt='g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(alpha_review_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination Model\n",
      "Cross Validation Balanced Accuracy (Train Data):  [0.68800875 0.66936002 0.68409149 0.68336626 0.68633028]\n",
      "Balanced Accuracy of Cross Val : 0.68 (+/- 0.01)\n",
      "Balanced Accuracy Score (Test Data):  0.6954987330601589\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.59       410\n",
      "           1       0.41      0.61      0.49       493\n",
      "           2       0.96      0.88      0.92      3031\n",
      "\n",
      "    accuracy                           0.81      3934\n",
      "   macro avg       0.65      0.70      0.66      3934\n",
      "weighted avg       0.85      0.81      0.83      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Combination Model')\n",
    "cross_score = cross_val_score(model_combination, alpha_combination_train, alpha_combination_y_train, scoring='balanced_accuracy')\n",
    "model_combination.fit(alpha_combination_train, alpha_combination_y_train)\n",
    "y_pred = model_combination.predict(alpha_combination_test)\n",
    "score = balanced_accuracy_score(alpha_combination_y_test, y_pred)\n",
    "print('Cross Validation Balanced Accuracy (Train Data): ', cross_score)\n",
    "print(\"Balanced Accuracy of Cross Val : %0.2f (+/- %0.2f)\" % (cross_score.mean(), cross_score.std() * 2))\n",
    "print('Balanced Accuracy Score (Test Data): ', score)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_matrix(alpha_combination_y_test, y_pred), annot=True, fmt='g')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(alpha_combination_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our model has a hard time predicting Neutral and Negative Sentiments, this is because our data is heavily imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "Our model can predict the word **love** really well, but has a hard time predicting the word **hate** which is suppose to be a Negative sentiment.\n",
    "\n",
    "Looking at the dataset more closely, it's because there are a lot of text with **love** and **hate** in it, that's why the model is confused. But with this accuracy for first time project, i think it's good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[[0.01954736 0.01167093 0.96878171]]\n",
      "[2]\n",
      "[[4.61086798e-04 1.30339719e-03 9.98235516e-01]]\n",
      "[2]\n",
      "[[3.33282026e-05 1.00094176e-04 9.99866578e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(model_title.predict(['i love it']))\n",
    "print(model_title.predict_proba(['i love it']))\n",
    "\n",
    "print(model_review.predict(['i really love this dress it has everything i need']))\n",
    "print(model_review.predict_proba(['i really love this dress it has everything i need']))\n",
    "\n",
    "print(model_combination.predict(['i love it i really love this dress it has everything i need']))\n",
    "print(model_combination.predict_proba(['i love it i really love this dress it has everything i need']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[[0.27812962 0.2670769  0.45479349]]\n",
      "[1]\n",
      "[[0.23009989 0.5525669  0.21733321]]\n",
      "[1]\n",
      "[[0.19316074 0.62291562 0.18392364]]\n"
     ]
    }
   ],
   "source": [
    "print(model_title.predict(['i hate it']))\n",
    "print(model_title.predict_proba(['i hate it']))\n",
    "\n",
    "print(model_review.predict(['i hate how this dress makes me look']))\n",
    "print(model_review.predict_proba(['i hate how this dress makes me look']))\n",
    "\n",
    "print(model_combination.predict(['i hate it i hate how this dress makes me look']))\n",
    "print(model_combination.predict_proba(['i hate it i hate how this dress makes me look']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_title</th>\n",
       "      <th>stem_title</th>\n",
       "      <th>lemma_title</th>\n",
       "      <th>alpha_review</th>\n",
       "      <th>stem_review</th>\n",
       "      <th>lemma_review</th>\n",
       "      <th>alpha_combination</th>\n",
       "      <th>stem_combination</th>\n",
       "      <th>lemma_combination</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>love this dress   hate the lining</td>\n",
       "      <td>love dress hate line</td>\n",
       "      <td>love dress hate lining</td>\n",
       "      <td>i love this dress and have already worn it a c...</td>\n",
       "      <td>love dress alreadi worn coupl time sinc purcha...</td>\n",
       "      <td>love dress already worn couple time since purc...</td>\n",
       "      <td>love this dress   hate the lining  i love this...</td>\n",
       "      <td>love dress hate line love dress alreadi worn c...</td>\n",
       "      <td>love dress hate lining love dress already worn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343</th>\n",
       "      <td>love hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>i love these jeans  they are really cute and c...</td>\n",
       "      <td>love jean realli cute comfi howev way long bel...</td>\n",
       "      <td>love jean really cute comfy however way long b...</td>\n",
       "      <td>love hate i love these jeans  they are really ...</td>\n",
       "      <td>love hate love jean realli cute comfi howev wa...</td>\n",
       "      <td>love hate love jean really cute comfy however ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8378</th>\n",
       "      <td>love hate relationship with this dress</td>\n",
       "      <td>love hate relationship dress</td>\n",
       "      <td>love hate relationship dress</td>\n",
       "      <td>i love the look of this dress  the fitting cou...</td>\n",
       "      <td>love look dress fit could use work top layer c...</td>\n",
       "      <td>love look dress fitting could use work top lay...</td>\n",
       "      <td>love hate relationship with this dress i love ...</td>\n",
       "      <td>love hate relationship dress love look dress f...</td>\n",
       "      <td>love hate relationship dress love look dress f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8577</th>\n",
       "      <td>love and hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>i was excited when i saw these shorts in my lo...</td>\n",
       "      <td>excit saw short local retail store wear someti...</td>\n",
       "      <td>excite saw short local retailer store wear som...</td>\n",
       "      <td>love and hate i was excited when i saw these s...</td>\n",
       "      <td>love hate excit saw short local retail store w...</td>\n",
       "      <td>love hate excite saw short local retailer stor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>cute  but hate the side zipper</td>\n",
       "      <td>cute hate side zipper</td>\n",
       "      <td>cute hate side zipper</td>\n",
       "      <td>i love charlie trousers  i must have   pair  i...</td>\n",
       "      <td>love charli trouser must pair sometim bought p...</td>\n",
       "      <td>love charlie trouser must pair sometimes bough...</td>\n",
       "      <td>cute  but hate the side zipper i love charlie ...</td>\n",
       "      <td>cute hate side zipper love charli trouser must...</td>\n",
       "      <td>cute hate side zipper love charlie trouser mus...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11407</th>\n",
       "      <td>love the print  hate the fit</td>\n",
       "      <td>love print hate fit</td>\n",
       "      <td>love print hate fit</td>\n",
       "      <td>i have a love hate relationship with this dres...</td>\n",
       "      <td>love hate relationship dress fabric print beau...</td>\n",
       "      <td>love hate relationship dress fabric print beau...</td>\n",
       "      <td>love the print  hate the fit i have a love hat...</td>\n",
       "      <td>love print hate fit love hate relationship dre...</td>\n",
       "      <td>love print hate fit love hate relationship dre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13323</th>\n",
       "      <td>love hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>i have a love hate relationship with these jea...</td>\n",
       "      <td>love hate relationship jean first put felt lik...</td>\n",
       "      <td>love hate relationship jean first put felt lik...</td>\n",
       "      <td>love hate i have a love hate relationship with...</td>\n",
       "      <td>love hate love hate relationship jean first pu...</td>\n",
       "      <td>love hate love hate relationship jean first pu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14736</th>\n",
       "      <td>love and hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>this is a beautiful vest  i love the color blo...</td>\n",
       "      <td>beauti vest love color block modern structur s...</td>\n",
       "      <td>beautiful vest love color block modern structu...</td>\n",
       "      <td>love and hate  this is a beautiful vest  i lov...</td>\n",
       "      <td>love hate beauti vest love color block modern ...</td>\n",
       "      <td>love hate beautiful vest love color block mode...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15636</th>\n",
       "      <td>love the style   hate the dye left on my skin</td>\n",
       "      <td>love style hate dye left skin</td>\n",
       "      <td>love style hate dye leave skin</td>\n",
       "      <td>i recommend this product  but with the followi...</td>\n",
       "      <td>recommend product follow reserv dye product co...</td>\n",
       "      <td>recommend product follow reservation dye produ...</td>\n",
       "      <td>love the style   hate the dye left on my skin ...</td>\n",
       "      <td>love style hate dye left skin recommend produc...</td>\n",
       "      <td>love style hate dye leave skin recommend produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15650</th>\n",
       "      <td>love hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>love hate</td>\n",
       "      <td>i love this jump suit   sorta  looks great on ...</td>\n",
       "      <td>love jump suit sorta look great dye rub skin w...</td>\n",
       "      <td>love jump suit sorta look great dye rub skin w...</td>\n",
       "      <td>love hate i love this jump suit   sorta  looks...</td>\n",
       "      <td>love hate love jump suit sorta look great dye ...</td>\n",
       "      <td>love hate love jump suit sorta look great dye ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17136</th>\n",
       "      <td>love the design  hate the itchiness</td>\n",
       "      <td>love design hate itchi</td>\n",
       "      <td>love design hate itchiness</td>\n",
       "      <td>my title perfectly describes my attitude towar...</td>\n",
       "      <td>titl perfect describ attitud toward sweater pr...</td>\n",
       "      <td>title perfectly describe attitude toward sweat...</td>\n",
       "      <td>love the design  hate the itchiness  my title ...</td>\n",
       "      <td>love design hate itchi titl perfect describ at...</td>\n",
       "      <td>love design hate itchiness title perfectly des...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17928</th>\n",
       "      <td>love rockets  hated these</td>\n",
       "      <td>love rocket hate</td>\n",
       "      <td>love rocket hat</td>\n",
       "      <td>recently started loving rockets  i own a pair ...</td>\n",
       "      <td>recent start love rocket pair black pair distr...</td>\n",
       "      <td>recently start love rocket pair black pair dis...</td>\n",
       "      <td>love rockets  hated these recently started lov...</td>\n",
       "      <td>love rocket hate recent start love rocket pair...</td>\n",
       "      <td>love rocket hat recently start love rocket pai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         alpha_title  \\\n",
       "3106              love this dress   hate the lining    \n",
       "5343                                       love hate   \n",
       "8378          love hate relationship with this dress   \n",
       "8577                                   love and hate   \n",
       "10884                 cute  but hate the side zipper   \n",
       "11407                   love the print  hate the fit   \n",
       "13323                                      love hate   \n",
       "14736                                 love and hate    \n",
       "15636  love the style   hate the dye left on my skin   \n",
       "15650                                      love hate   \n",
       "17136           love the design  hate the itchiness    \n",
       "17928                      love rockets  hated these   \n",
       "\n",
       "                          stem_title                     lemma_title  \\\n",
       "3106            love dress hate line          love dress hate lining   \n",
       "5343                       love hate                       love hate   \n",
       "8378    love hate relationship dress    love hate relationship dress   \n",
       "8577                       love hate                       love hate   \n",
       "10884          cute hate side zipper           cute hate side zipper   \n",
       "11407            love print hate fit             love print hate fit   \n",
       "13323                      love hate                       love hate   \n",
       "14736                      love hate                       love hate   \n",
       "15636  love style hate dye left skin  love style hate dye leave skin   \n",
       "15650                      love hate                       love hate   \n",
       "17136         love design hate itchi      love design hate itchiness   \n",
       "17928               love rocket hate                 love rocket hat   \n",
       "\n",
       "                                            alpha_review  \\\n",
       "3106   i love this dress and have already worn it a c...   \n",
       "5343   i love these jeans  they are really cute and c...   \n",
       "8378   i love the look of this dress  the fitting cou...   \n",
       "8577   i was excited when i saw these shorts in my lo...   \n",
       "10884  i love charlie trousers  i must have   pair  i...   \n",
       "11407  i have a love hate relationship with this dres...   \n",
       "13323  i have a love hate relationship with these jea...   \n",
       "14736  this is a beautiful vest  i love the color blo...   \n",
       "15636  i recommend this product  but with the followi...   \n",
       "15650  i love this jump suit   sorta  looks great on ...   \n",
       "17136  my title perfectly describes my attitude towar...   \n",
       "17928  recently started loving rockets  i own a pair ...   \n",
       "\n",
       "                                             stem_review  \\\n",
       "3106   love dress alreadi worn coupl time sinc purcha...   \n",
       "5343   love jean realli cute comfi howev way long bel...   \n",
       "8378   love look dress fit could use work top layer c...   \n",
       "8577   excit saw short local retail store wear someti...   \n",
       "10884  love charli trouser must pair sometim bought p...   \n",
       "11407  love hate relationship dress fabric print beau...   \n",
       "13323  love hate relationship jean first put felt lik...   \n",
       "14736  beauti vest love color block modern structur s...   \n",
       "15636  recommend product follow reserv dye product co...   \n",
       "15650  love jump suit sorta look great dye rub skin w...   \n",
       "17136  titl perfect describ attitud toward sweater pr...   \n",
       "17928  recent start love rocket pair black pair distr...   \n",
       "\n",
       "                                            lemma_review  \\\n",
       "3106   love dress already worn couple time since purc...   \n",
       "5343   love jean really cute comfy however way long b...   \n",
       "8378   love look dress fitting could use work top lay...   \n",
       "8577   excite saw short local retailer store wear som...   \n",
       "10884  love charlie trouser must pair sometimes bough...   \n",
       "11407  love hate relationship dress fabric print beau...   \n",
       "13323  love hate relationship jean first put felt lik...   \n",
       "14736  beautiful vest love color block modern structu...   \n",
       "15636  recommend product follow reservation dye produ...   \n",
       "15650  love jump suit sorta look great dye rub skin w...   \n",
       "17136  title perfectly describe attitude toward sweat...   \n",
       "17928  recently start love rocket pair black pair dis...   \n",
       "\n",
       "                                       alpha_combination  \\\n",
       "3106   love this dress   hate the lining  i love this...   \n",
       "5343   love hate i love these jeans  they are really ...   \n",
       "8378   love hate relationship with this dress i love ...   \n",
       "8577   love and hate i was excited when i saw these s...   \n",
       "10884  cute  but hate the side zipper i love charlie ...   \n",
       "11407  love the print  hate the fit i have a love hat...   \n",
       "13323  love hate i have a love hate relationship with...   \n",
       "14736  love and hate  this is a beautiful vest  i lov...   \n",
       "15636  love the style   hate the dye left on my skin ...   \n",
       "15650  love hate i love this jump suit   sorta  looks...   \n",
       "17136  love the design  hate the itchiness  my title ...   \n",
       "17928  love rockets  hated these recently started lov...   \n",
       "\n",
       "                                        stem_combination  \\\n",
       "3106   love dress hate line love dress alreadi worn c...   \n",
       "5343   love hate love jean realli cute comfi howev wa...   \n",
       "8378   love hate relationship dress love look dress f...   \n",
       "8577   love hate excit saw short local retail store w...   \n",
       "10884  cute hate side zipper love charli trouser must...   \n",
       "11407  love print hate fit love hate relationship dre...   \n",
       "13323  love hate love hate relationship jean first pu...   \n",
       "14736  love hate beauti vest love color block modern ...   \n",
       "15636  love style hate dye left skin recommend produc...   \n",
       "15650  love hate love jump suit sorta look great dye ...   \n",
       "17136  love design hate itchi titl perfect describ at...   \n",
       "17928  love rocket hate recent start love rocket pair...   \n",
       "\n",
       "                                       lemma_combination  Sentiment  \n",
       "3106   love dress hate lining love dress already worn...          2  \n",
       "5343   love hate love jean really cute comfy however ...          1  \n",
       "8378   love hate relationship dress love look dress f...          1  \n",
       "8577   love hate excite saw short local retailer stor...          2  \n",
       "10884  cute hate side zipper love charlie trouser mus...          2  \n",
       "11407  love print hate fit love hate relationship dre...          1  \n",
       "13323  love hate love hate relationship jean first pu...          1  \n",
       "14736  love hate beautiful vest love color block mode...          0  \n",
       "15636  love style hate dye leave skin recommend produ...          0  \n",
       "15650  love hate love jump suit sorta look great dye ...          0  \n",
       "17136  love design hate itchiness title perfectly des...          1  \n",
       "17928  love rocket hat recently start love rocket pai...          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment[df_sentiment['alpha_title'].isin([i for i in df_sentiment['alpha_title'] if 'hate' in i])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- The model i chose for this project ended up being **Multinomial Naive Bayes**\n",
    "- The processed text data best for this ended up being the **Alphabet-only Lowered Text Data**\n",
    "- Due to Imbalanced Dataset, our model had a hard time predicting the minority classes and thus only able to achieve a **Balanced Accuracy Score of 60-70%**\n",
    "\n",
    "## Possible Solutions\n",
    "\n",
    "Because only reaching a 60-70% is not that good, i believe there should be other things we could do to improve this model, but because lack of time, computation power, and experience i couldn't do it. Those things are:\n",
    "\n",
    "- Do a lexicon-based approach, where instead of doing bag of words, train the machine learning model on the meaning of the words too, to achieve better understanding of the text data\n",
    "- Use Oversampling technique such as SMOTE to deal with the imbalanced dataset\n",
    "- Use Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_title, open('model_title.sav', 'wb'))\n",
    "pickle.dump(model_review, open('model_review.sav', 'wb'))\n",
    "pickle.dump(model_combination, open('model_combination.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
